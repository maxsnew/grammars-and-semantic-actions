
@inproceedings{lautemann_logics_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Logics for context-free languages},
	isbn = {978-3-540-49404-1},
	doi = {10.1007/BFb0022257},
	abstract = {We define matchings, and show that they capture the essence of context-freeness. More precisely, we show that the class of context-free languages coincides with the class of those sets of strings which can be defined by sentences of the form ∃ bϕ, where ϕ is first order, b is a binary predicate symbol, and the range of the second order quantifier is restricted to the class of matchings. Several variations and extensions are discussed.},
	language = {en},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer},
	author = {Lautemann, Clemens and Schwentick, Thomas and Thérien, Denis},
	editor = {Pacholski, Leszek and Tiuryn, Jerzy},
	year = {1995},
	pages = {205--216},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/K8WPLXLQ/Lautemann et al. - 1995 - Logics for context-free languages.pdf:application/pdf},
}

@article{henglein_regular_2011,
	title = {Regular expression containment: coinductive axiomatization and computational interpretation},
	volume = {46},
	issn = {0362-1340},
	shorttitle = {Regular expression containment},
	url = {https://dl.acm.org/doi/10.1145/1925844.1926429},
	doi = {10.1145/1925844.1926429},
	abstract = {We present a new sound and complete axiomatization of regular expression containment. It consists of the conventional axiomatization of concatenation, alternation, empty set and (the singleton set containing) the empty string as an idempotent semiring, the fixed- point rule E* = 1 + E × E* for Kleene-star, and a general coinduction rule as the only additional rule. Our axiomatization gives rise to a natural computational interpretation of regular expressions as simple types that represent parse trees, and of containment proofs as coercions. This gives the axiom- atization a Curry-Howard-style constructive interpretation: Containment proofs do not only certify a language-theoretic contain- ment, but, under our computational interpretation, constructively transform a membership proof of a string in one regular expression into a membership proof of the same string in another regular expression. We show how to encode regular expression equivalence proofs in Salomaa's, Kozen's and Grabmayer's axiomatizations into our containment system, which equips their axiomatizations with a computational interpretation and implies completeness of our axiomatization. To ensure its soundness, we require that the computational interpretation of the coinduction rule be a hereditarily total function. Hereditary totality can be considered the mother of syn- tactic side conditions: it "explains" their soundness, yet cannot be used as a conventional side condition in its own right since it turns out to be undecidable. We discuss application of regular expressions as types to bit coding of strings and hint at other applications to the wide-spread use of regular expressions for substring matching, where classical automata-theoretic techniques are a priori inapplicable. Neither regular expressions as types nor subtyping interpreted coercively are novel per se. Somewhat surprisingly, this seems to be the first investigation of a general proof-theoretic framework for the latter in the context of the former, however.},
	number = {1},
	urldate = {2023-11-28},
	journal = {ACM SIGPLAN Notices},
	author = {Henglein, Fritz and Nielsen, Lasse},
	month = jan,
	year = {2011},
	keywords = {axiomatization, coercion, coinduction, computational interpretation, containment, equivalence, regular expression, type},
	pages = {385--398},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/ZUZHNIP8/Henglein and Nielsen - 2011 - Regular expression containment coinductive axioma.pdf:application/pdf},
}

@article{grathwohl_infinitary_2013,
	title = {Infinitary {Axiomatization} of the {Equational} {Theory} of {Context}-{Free} {Languages}},
	volume = {126},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1309.0893},
	doi = {10.4204/EPTCS.126.4},
	abstract = {We give a natural complete infinitary axiomatization of the equational theory of the context-free languages, answering a question of Lei\{{\textbackslash}ss\} (1992).},
	urldate = {2023-11-28},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Grathwohl, Niels Bjørn Bugge and Henglein, Fritz and Kozen, Dexter},
	month = aug,
	year = {2013},
	note = {arXiv:1309.0893 [cs]},
	keywords = {Computer Science - Formal Languages and Automata Theory, Computer Science - Logic in Computer Science},
	pages = {44--55},
	file = {arXiv Fulltext PDF:/Users/stevenschaefer/Zotero/storage/TJHAX5RI/Grathwohl et al. - 2013 - Infinitary Axiomatization of the Equational Theory.pdf:application/pdf;arXiv.org Snapshot:/Users/stevenschaefer/Zotero/storage/INYKMZZH/1309.html:text/html},
}

@inproceedings{krishnaswami_integrating_2015,
	address = {Mumbai India},
	title = {Integrating {Linear} and {Dependent} {Types}},
	isbn = {978-1-4503-3300-9},
	url = {https://dl.acm.org/doi/10.1145/2676726.2676969},
	doi = {10.1145/2676726.2676969},
	abstract = {In this paper, we show how to integrate linear types with type dependency, by extending the linear/non-linear calculus of Benton to support type dependency.},
	language = {en},
	urldate = {2024-01-04},
	booktitle = {Proceedings of the 42nd {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Krishnaswami, Neelakantan R. and Pradic, Pierre and Benton, Nick},
	month = jan,
	year = {2015},
	pages = {17--30},
	file = {Krishnaswami et al. - 2015 - Integrating Linear and Dependent Types.pdf:/Users/stevenschaefer/Zotero/storage/867QYE2N/Krishnaswami et al. - 2015 - Integrating Linear and Dependent Types.pdf:application/pdf},
}

@article{hyland_glueing_2003,
	title = {Glueing and orthogonality for models of linear logic},
	volume = {294},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397501002419},
	doi = {10.1016/S0304-3975(01)00241-9},
	abstract = {We present the general theory of the method of glueing and associated technique of orthogonality for constructing categorical models of all the structure of linear logic: in particular we treat the exponentials in detail. We indicate simple applications of the methods and show that they cover familiar examples. c 2002 Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {1-2},
	urldate = {2024-03-04},
	journal = {Theoretical Computer Science},
	author = {Hyland, Martin and Schalk, Andrea},
	month = feb,
	year = {2003},
	pages = {183--231},
	file = {Hyland and Schalk - 2003 - Glueing and orthogonality for models of linear log.pdf:/Users/stevenschaefer/Zotero/storage/EZ43SYGH/Hyland and Schalk - 2003 - Glueing and orthogonality for models of linear log.pdf:application/pdf},
}

@inproceedings{krishnaswami_typed_2019,
	address = {Phoenix AZ USA},
	title = {A typed, algebraic approach to parsing},
	isbn = {978-1-4503-6712-7},
	url = {https://dl.acm.org/doi/10.1145/3314221.3314625},
	doi = {10.1145/3314221.3314625},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Proceedings of the 40th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Krishnaswami, Neelakantan R. and Yallop, Jeremy},
	month = jun,
	year = {2019},
	pages = {379--393},
	file = {Krishnaswami and Yallop - 2019 - A typed, algebraic approach to parsing.pdf:/Users/stevenschaefer/Zotero/storage/HUS3NZFK/Krishnaswami and Yallop - 2019 - A typed, algebraic approach to parsing.pdf:application/pdf},
}

@article{leroy_formal_2009,
	title = {Formal verification of a realistic compiler},
	volume = {52},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/1538788.1538814},
	doi = {10.1145/1538788.1538814},
	abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
	language = {en},
	number = {7},
	urldate = {2024-04-22},
	journal = {Communications of the ACM},
	author = {Leroy, Xavier},
	month = jul,
	year = {2009},
	pages = {107--115},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/UW7FUAX2/Leroy - 2009 - Formal verification of a realistic compiler.pdf:application/pdf},
}

@inproceedings{kumar_cakeml_2014,
	address = {San Diego California USA},
	title = {{CakeML}: a verified implementation of {ML}},
	isbn = {978-1-4503-2544-8},
	shorttitle = {{CakeML}},
	url = {https://dl.acm.org/doi/10.1145/2535838.2535841},
	doi = {10.1145/2535838.2535841},
	abstract = {We have developed and mechanically veriﬁed an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our veriﬁcation effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitraryprecision arithmetic, and compiler bootstrapping.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kumar, Ramana and Myreen, Magnus O. and Norrish, Michael and Owens, Scott},
	month = jan,
	year = {2014},
	pages = {179--191},
	file = {Kumar et al. - 2014 - CakeML a verified implementation of ML.pdf:/Users/stevenschaefer/Zotero/storage/L2QPEHF2/Kumar et al. - 2014 - CakeML a verified implementation of ML.pdf:application/pdf},
}


@article{yangFindingUnderstandingBugs,
	title = {Finding and {Understanding} {Bugs} in {C} {Compilers}},
	abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to ﬁnd compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our ﬁrst contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undeﬁned and unspeciﬁed behaviors that would destroy its ability to automatically ﬁnd wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
	language = {en},
	author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
	file = {Yang et al. - Finding and Understanding Bugs in C Compilers.pdf:/Users/stevenschaefer/Zotero/storage/6ZSM5RDR/Yang et al. - Finding and Understanding Bugs in C Compilers.pdf:application/pdf},
}

@incollection{jourdanValidatingLRParsers2012,
	address = {Berlin, Heidelberg},
	title = {Validating {LR}(1) {Parsers}},
	volume = {7211},
	isbn = {978-3-642-28868-5 978-3-642-28869-2},
	url = {http://link.springer.com/10.1007/978-3-642-28869-2_20},
	abstract = {An LR(1) parser is a ﬁnite-state automaton, equipped with a stack, which uses a combination of its current state and one lookahead symbol in order to determine which action to perform next. We present a validator which, when applied to a context-free grammar G and an automaton A, checks that A and G agree. Validating the parser provides the correctness guarantees required by veriﬁed compilers and other high-assurance software that involves parsing. The validation process is independent of which technique was used to construct A. The validator is implemented and proved correct using the Coq proof assistant. As an application, we build a formally-veriﬁed parser for the C99 language.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Jourdan, Jacques-Henri and Pottier, François and Leroy, Xavier},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Seidl, Helmut},
	year = {2012},
	doi = {10.1007/978-3-642-28869-2_20},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {397--416},
	file = {Jourdan et al. - 2012 - Validating LR(1) Parsers.pdf:/Users/stevenschaefer/Zotero/storage/UJQGN33D/Jourdan et al. - 2012 - Validating LR(1) Parsers.pdf:application/pdf},
}

@incollection{bentonMixedLinearNonlinear1995,
	address = {Berlin, Heidelberg},
	title = {A mixed linear and non-linear logic: {Proofs}, terms and models: {Extended} abstract},
	volume = {933},
	isbn = {978-3-540-60017-6 978-3-540-49404-1},
	shorttitle = {A mixed linear and non-linear logic},
	url = {http://link.springer.com/10.1007/BFb0022251},
	abstract = {Intuitionistic linear logic regains the expressive power of intuitionistic logic through the ! ('of course') modality. Benton, Bierman, Hyland and de Paiva have given a term assignment system for ILL and an associated notion of categorical model in which the ! modality is modelled by a comonad satisfying certain extra conditions. Ordinary intuitionistic logic is then modelled in a cartesian dosed category which arises as a full subcategory of the category of coalgebras for the comonad. This paper attempts to explain the connection between ILL and IL more directly and symmetricallyby giving a logic, term calculus and categorical model for a system in which the linear and non-linear worlds exist on an equal footing, with operations allowing one to pass in both directions. We start from the categorical model of ILL given by Benton, Bierman, Hyland and de Paiva and show that this is equivalent to having a symmetric monoidal adjunction between a symmetric monoidal dosed category and a cartesian closed category. We then derive both a sequent calculus and a natural deduction presentation of the logic corresponding to the new notion of model.},
	language = {en},
	urldate = {2024-04-27},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer Berlin Heidelberg},
	author = {Benton, P. N.},
	editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Pacholski, Leszek and Tiuryn, Jerzy},
	year = {1995},
	doi = {10.1007/BFb0022251},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {121--135},
	file = {BFb0022251.pdf:/Users/stevenschaefer/Downloads/BFb0022251.pdf:application/pdf},
}

@article{brzozowskiDerivativesRegularExpressions1964,
	title = {Derivatives of {Regular} {Expressions}},
	volume = {11},
	issn = {0004-5411, 1557-735X},
	url = {https://dl.acm.org/doi/10.1145/321239.321249},
	doi = {10.1145/321239.321249},
	language = {en},
	number = {4},
	urldate = {2024-04-29},
	journal = {Journal of the ACM},
	author = {Brzozowski, Janusz A.},
	month = oct,
	year = {1964},
	pages = {481--494},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/CMQXUWQR/Brzozowski - 1964 - Derivatives of Regular Expressions.pdf:application/pdf},
}

@inproceedings{mightParsingDerivativesFunctional2011,
	address = {Tokyo Japan},
	title = {Parsing with derivatives: a functional pearl},
	isbn = {978-1-4503-0865-6},
	shorttitle = {Parsing with derivatives},
	url = {https://dl.acm.org/doi/10.1145/2034773.2034801},
	doi = {10.1145/2034773.2034801},
	language = {en},
	urldate = {2024-04-29},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} international conference on {Functional} programming},
	publisher = {ACM},
	author = {Might, Matthew and Darais, David and Spiewak, Daniel},
	month = sep,
	year = {2011},
	pages = {189--195},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/Y99XZYVR/Might et al. - 2011 - Parsing with derivatives a functional pearl.pdf:application/pdf},
}

@article{rabinFiniteAutomataTheir1959,
	title = {Finite {Automata} and {Their} {Decision} {Problems}},
	volume = {3},
	issn = {0018-8646, 0018-8646},
	url = {http://ieeexplore.ieee.org/document/5392601/},
	doi = {10.1147/rd.32.0114},
	abstract = {Finite automata are considered in this paper as instruments for classifying finite tapes. Each onetape automaton defines a set of tapes, a two-tape automaton defines a set of pairs of tapes, et cetera. The structure of the defined sets is studied. Various generalizations of the notion of an automaton are introduced and their relation to the classical automata is determined. Some decision problems concerning automata are shown to be solvable by effective algorithms; others turn out to be unsolvable by algorithms.},
	language = {en},
	number = {2},
	urldate = {2024-04-29},
	journal = {IBM Journal of Research and Development},
	author = {Rabin, M. O. and Scott, D.},
	month = apr,
	year = {1959},
	pages = {114--125},
	file = {Rabin and Scott - 1959 - Finite Automata and Their Decision Problems.pdf:/Users/stevenschaefer/Zotero/storage/V4PSR9SW/Rabin and Scott - 1959 - Finite Automata and Their Decision Problems.pdf:application/pdf},
}


@article{owensRegularexpressionDerivativesReexamined2009,
	title = {Regular-expression derivatives re-examined},
	volume = {19},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796808007090/type/journal_article},
	doi = {10.1017/S0956796808007090},
	abstract = {Abstract
            Regular-expression derivatives are an old, but elegant, technique for compiling regular expressions to deterministic finite-state machines. It easily supports extending the regular-expression operators with boolean operations, such as intersection and complement. Unfortunately, this technique has been lost in the sands of time and few computer scientists are aware of it. In this paper, we reexamine regular-expression derivatives and report on our experiences in the context of two different functional-language implementations. The basic implementation is simple and we show how to extend it to handle large character sets (e.g., Unicode). We also show that the derivatives approach leads to smaller state machines than the traditional algorithm given by McNaughton and Yamada.},
	language = {en},
	number = {2},
	urldate = {2024-04-29},
	journal = {Journal of Functional Programming},
	author = {Owens, Scott and Reppy, John and Turon, Aaron},
	month = mar,
	year = {2009},
	pages = {173--190},
	file = {Owens et al. - 2009 - Regular-expression derivatives re-examined.pdf:/Users/stevenschaefer/Zotero/storage/PQB9TTVL/Owens et al. - 2009 - Regular-expression derivatives re-examined.pdf:application/pdf},
}


@article{thompsonProgrammingTechniquesRegular1968,
	title = {Programming {Techniques}: {Regular} expression search algorithm},
	volume = {11},
	issn = {0001-0782, 1557-7317},
	shorttitle = {Programming {Techniques}},
	url = {https://dl.acm.org/doi/10.1145/363347.363387},
	doi = {10.1145/363347.363387},
	abstract = {A method for locating specific character strings embedded in character text is described and an implementation of this method in the form of a compiler is discussed. The compiler accepts a regular expression as source language and produces an IBM 7094 program as object language. The object program then accepts the text to be searched as input and produces a signal every time an embedded string in the text matches the given regular expression. Examples, problems, and solutions are also presented.},
	language = {en},
	number = {6},
	urldate = {2024-04-29},
	journal = {Communications of the ACM},
	author = {Thompson, Ken},
	month = jun,
	year = {1968},
	pages = {419--422},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/6FRSL8GN/Thompson - 1968 - Programming Techniques Regular expression search .pdf:application/pdf},
}


@incollection{Bekić1984,
	address = {Berlin, Heidelberg},
	title = {Definable operations in general algebras, and the theory of automata and flowcharts},
	isbn = {978-3-540-38933-0},
	url = {https://doi.org/10.1007/BFb0048939},
	abstract = {We study the class of operations definable from the given operations of an algebra of sets by union, composition, and fixed points; we obtain two theorems on definable operations that give us as special case the regular-equals-recognisable theorem of generalised finite automata theory. Definable operations arise also as the operations computable by charts; by translating into predicate logic, we obtain Manna's formulas for termination and correctness of flowcharts.},
	booktitle = {Programming languages and their definition: {H}. {Bekič} (1936–1982)},
	publisher = {Springer Berlin Heidelberg},
	author = {Bekić, Hans},
	editor = {Jones, C. B.},
	year = {1984},
	doi = {10.1007/BFb0048939},
	pages = {30--55},
}


@article{zhangIntervalParsingGrammars2023,
	title = {Interval {Parsing} {Grammars} for {File} {Format} {Parsing}},
	volume = {7},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3591264},
	doi = {10.1145/3591264},
	abstract = {File formats specify how data is encoded for persistent storage. They cannot be formalized as context-free grammars since their specifications include context-sensitive patterns such as the random access pattern and the type-length-value pattern. We propose a new grammar mechanism called Interval Parsing Grammars IPGs) for file format specifications. An IPG attaches to every nonterminal/terminal an interval, which specifies the range of input the nonterminal/terminal consumes. By connecting intervals and attributes, the context-sensitive patterns in file formats can be well handled. In this paper, we formalize IPGs' syntax as well as its semantics, and its semantics naturally leads to a parser generator that generates a recursive-descent parser from an IPG. In general, IPGs are declarative, modular, and enable termination checking. We have used IPGs to specify a number of file formats including ZIP, ELF, GIF, PE, and part of PDF; we have also evaluated the performance of the generated parsers.},
	language = {en},
	number = {PLDI},
	urldate = {2024-04-29},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Zhang, Jialun and Morrisett, Greg and Tan, Gang},
	month = jun,
	year = {2023},
	pages = {1073--1095},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/4JNN3FNZ/Zhang et al. - 2023 - Interval Parsing Grammars for File Format Parsing.pdf:application/pdf},
}

@article{chom1963,
  title        = {Formal Properties of Grammars},
  author       = {Noam Chomsky},
  year         = 1963,
  journal      = {Handbook of Mathematical Psychology},
  volume       = II,
  pages        = {323--418},
}
