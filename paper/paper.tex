\documentclass[sigconf,anonymous,review,screen]{acmart}
\usepackage{mathpartir}
\usepackage{tikz-cd}
\usepackage{enumitem}
\usepackage{wrapfig}
\usepackage{fancyvrb}
\usepackage{stmaryrd}

\newcommand{\cat}[1]{\mathbf{#1}}
\newcommand{\lto}{\multimap}
\newcommand{\tol}{\rotatebox[origin=c]{180}{$\lto$}}
\newcommand{\Set}{\mathbf{Set}}
\newcommand{\Type}{\mathbf{Type}}
\newcommand{\Prop}{\mathbf{Prop}}
\newcommand{\Bool}{\mathbf{Bool}}

\newcommand{\subst}[3]{#1\{#2/#3\}}
\newcommand{\letin}[3]{\mathsf{let}\, #1 = #2 \, \mathsf{in}\, #3}
\newcommand{\lamb}[2]{\lambda #1.\, #2}
\newcommand{\dlamb}[2]{\hat{\lambda} #1.\, #2}
\newcommand{\app}[2]{#1 \, #2}
\newcommand{\PiTy}[3]{\Pi #1 : #2.\, #3}
\newcommand{\SigTy}[3]{\Sigma #1 : #2.\, #3}
\newcommand{\LinPiTy}[3]{\widebar\Pi #1 : #2.\, #3}
\newcommand{\LinSigTy}[3]{\widebar\Sigma #1 : #2.\, #3}
\newcommand{\amp}{\mathrel{\&}}
\newcommand{\GrTy}{\mathsf{Gr}}

\newcommand{\ctxwff}[1]{#1 \,\, \mathsf{ok}}
\newcommand{\ctxwffjdg}[2]{#1 \vdash #2 \,\, \mathsf{type}}
\newcommand{\linctxwff}[2]{#1 \vdash #2 \,\, \mathsf{ok}}
\newcommand{\linctxwffjdg}[2]{#1 \vdash #2 \,\, \mathsf{linear}}

\newif\ifdraft
\drafttrue
\newcommand{\steven}[1]{\ifdraft{\color{orange}[{\bf Steven}: #1]}\fi}
\renewcommand{\max}[1]{\ifdraft{\color{blue}[{\bf Max}: #1]}\fi}
\newcommand{\pedro}[1]{\ifdraft{\color{red}[{\bf Pedro}: #1]}\fi}
\newcommand{\pipe}{\,|\,}

%% Rights management information.  This information is sent to you
%% when you complete the rights form.  These commands have SAMPLE
%% values in them; it is your responsibility as an author to replace
%% the commands and values with those provided to you when you
%% complete the rights form.
\setcopyright{acmcopyright}
\copyrightyear{2018}
\acmYear{2018}
\acmDOI{XXXXXXX.XXXXXXX}

%% These commands are for a PROCEEDINGS abstract or paper.
\acmConference[Woodstock '18]{Woodstock '18: ACM Symposium on Neural
  Gaze Detection}{June 03--05, 2018}{Woodstock, NY}
\acmBooktitle{Woodstock '18: ACM Symposium on Neural Gaze Detection,
  June 03--05, 2018, Woodstock, NY}
\acmPrice{15.00}
\acmISBN{978-1-4503-XXXX-X/18/06}


\begin{document}
\title{Formal Grammars as Functors and Formal Grammars as Types in Non-commutative Bunched Type Theory}
\author{Steven Schaefer}
\affiliation{
  \department{Electrical Engineering and Computer Science}
  \institution{University of Michigan}
  \country{USA}
}
\email{stschaef@umich.edu}

\author{Max S. New}
\affiliation{
  \department{Electrical Engineering and Computer Science}
  \institution{University of Michigan}
  \country{USA}
}
\email{maxsnew@umich.edu}

\author{Pedro H. Azevedo de Amorim}
\affiliation{
  \department{Department of Computer Science}
  \institution{University of Oxford}
  \country{UK}
}
\email{pedro.azevedo.de.amorim@cs.ox.ac.uk}

\begin{abstract}
  We propose a semantic framework for the study of formal
  grammars. First, we provide a syntax-independent notion of formal
  grammar as a function from strings to sets, generalizing the
  familiar notion of a language as a set of strings. The set of such
  grammars naturally form a very rich category whose notion of
  isomorphism corresponds to strong equivalence of grammars, and for
  which many language-theoretic constructs can be defined using
  universal properties.

  Based on these category-theoretic constructions we propose a new
  syntactic formalism for formal grammars: a two-level non-commutative
  bunched dependent type theory whose types can be interpreted as
  grammars, and terms as parse transformers. The non-dependent
  fragment of this type theory is already enough to express
  regular/context-free expressions as well as finite automata,
  generalizing the language theoretic formalisms such as Kleene
  algebras to incorporate language ambiguity. By incorporating a
  restricted form of type dependency, we can further express indexed
  grammars, pushdown automata and Turing machines. This provides a new
  form of ``logical characterization'' of grammar classes based on a
  substructural logic rather than ordinary first-order logic. Further,
  the type theory can not only express the grammars as types, but
  equivalences between grammars and parsers as terms of the grammar.

  We give this type theory a semantics in our category of grammars and
  prove a canonicity theorem that shows that every term in a context
  corresponding to a fixed string is equal to a term in a canonical
  form encoding a parse tree of that string.
\end{abstract}

\maketitle

\section{A Syntax-Independent Notion of Syntax}

The theory of formal languages and parsing is one of the oldest and
most thoroughly developed areas of theoretical computer science. A
prominent topic in the 1950s and 60s led to a series of remarkable
developments: Chomsky's hierarchy of grammar formalisms, practical
algorithms for parsing of regular and context-free grammars and
variants, as well as implementations of practical tools for the
generation of efficient parsers.

A central notion is that of a \emph{formal language} $L$ over an
alphabet $\Sigma$ as simply a \emph{subset} of the set of strings $L
\subseteq \Sigma^*$. This definition is especially useful as it gives
a semantics to formal grammars that is completely independent of any
particular syntactic grammar formalism: any new notion of grammar can
be given a semantics in this common framework and it provides a
precise mathematical speicification for implementing a
\emph{recognizer} of a language and comparing the power of different
formalisms by demonstrating what languages can be formalized within
it. This also allows for completely \emph{language theoretic}
formulations of language classes: e.g., the regular \emph{languages}
can be characterized as those that have finitely many derivatives
\cite{brzozowski-or-myhill-nerode-idk}. This notion is remarkable
because it makes no reference to any specific syntactic formalism for
defining languages such as regular expressions or finite automata.

Formal language theory alone is not sufficient as a specification of a
parser: a language $L \subseteq \Sigma^*$ is equivalently defined as
its indicator function $\chi_L : \Sigma^* \to \Prop$ mapping each
string $w$ to the proposition that it is in the language $w \in
L$. This can then serve as the specification for a language
\emph{recognizer}: a program $r$ of type $\Sigma^* \to \Bool$ such
that $r(w) = \texttt{true}$ if and only if $\chi_L(w)$ holds, but
recognition is insufficient for most tasks for which the theory of
parsing was developed: the production of \emph{semantic} structures
from synactic descriptions in linguistics, compilation or
deserialization. The output of a parser is not just a boolean but a
\emph{parse tree}\footnote{such parse trees are usually not
materialized in memory, as the construction of the parse tree is fused
with application of semantic actions, which can be seen as a kind of
fold over the generated tree.}.

Due to this limitation, parsers are typically specified not by a
formal language, but by some \emph{formal grammar}, which specifies
not just \emph{which} strings are in the language but specifies what
are the \emph{parse trees} for the string. However unlike formal
language theory, there is no common universal notion of what
constitutes a formal grammar, but rather many syntactic systems such
as Chomskyan(?)  grammars, Thue systems, Montague grammars, etc which
are all syntactic presentations of the same underlying idea of an
abstract specification for parsing. The most common of these is the
Chomsky hierarchy of \emph{generative} grammars which specify parse
trees using \emph{derivations} of the string from a set of rewrite
rules, the parse tree encoding which rules were used.

Our first contribution is conceptual: we propose a simple,
syntax-independent definition of \emph{formal grammar}:
\begin{definition}
  A \emph{formal grammar} over an alphabet $\Sigma$ is a function
  $\Sigma^* \to \Set$.
\end{definition}
We say that a grammar $G$ associates to every string $w$ the set $Gw$
of \emph{parses} of that string. While we will work informally in this
paper, the collection $\Set$ can be formalized in many different
logical foundations: as a universe in type theory, a proper class in
set theory, etc. We argue that this is already a common intuition
latent in much prior work on grammars, especially when comparing
different formalisms for equivalence such as \cite{??}. This notion is
also completely natural in the context of constructive type theories
such as Agda which until recently did not include a universe of
propositions, and so for example in Elliott (\cite{??}) a formal
language was defined as a function to the universe $\Type$ with little
comment.

Every formal grammar $G$ induces a formal language, which can be seen
most easily by using the characteristic function formulation: we can
``squash'' any set into the proposition that it is inhabited, so
$\chi_G(w) = ||G(w)||$ which defines a subset $L_G = \{ w \in
\Sigma^*| G(w) \mathrm{inhabited}\}$.

Formal languages naturally arrange themselves into a partial order by
using the subset inclusion as the ordering. Formal grammars naturally
arrange themselves into a \emph{category} where a morphism $\alpha : G
\to H$ is given by a \emph{family} of functions
\[ \alpha^w : Gw \to Hw \]
for every string $w \in \Sigma^*$. The intuition is that a morphism of
grammars is a \emph{translation of parses}: a $G$-parse of $w$ gets
transformed to an $H$-parse of $w$. This then induces a notion of
\emph{isomorphism} of grammars: two grammars are equivalent if there
is a bijective translation of parses, precisely capturing the notion
of a \emph{strong equivalence} of grammars.

This category-theoretic framework can be further used to describe and
compare different notions of formal grammar. We can define a
\emph{notion of grammar} to be a category (or perhaps just groupoid)
paired with a functor into $\Set^{\Sigma^*}$. This naturally forms a
2-category the slice 2-category over $\Set^{\Sigma^*}$ and equivalence
in this 2-category defines a sensible notion of \emph{strong
equivalence of grammar formalisms} (TODO: check details).

The category of grammars is quite rich in structure, which can be most
easily observed from the fact that it is equivalently defined as the
category of functors $\Set^{\Sigma^*}$ where $\Sigma^*$ is here viewed
as a discrete category, that is, the objects are strings and only
morphisms are identity morphisms. Such functor categories, often
called presheaf categories, are incredibly rich in structure, which we
will exploit in section \ref{blah} to succinctly define the semantics
of regular and context-free grammars. \steven{Topoi model dependent type theory. This dependence is seemingly useful for also reasoning about context sensitivity, but this doesn't work for \textit{reasons}, right?}

\section{Kleene Category}

Kleene algebras are an important tool in the theory of regular
languages. More broadly, they serve as a theoretical substrate to
studying various kinds of formal languages. Formally, they are a tuple
$(A, +, \cdot, (-)^*, 1, 0)$, where $A$ is a set, $+$ and $\cdot$
are binary operations over $A$, $(-)^*$ is a function over $A$, and
$1$ and $0$ are constants. These structures satisfy the axoims depicted
in Figure~\ref{fig:axioms}.

\begin{figure}
  \begin{align*}
    x + (y + z) &= (x + y) + z & x + y &= y + x\\
    x + 0 &= x & x + x &= x\\
    x(yz) &= (xy)z & x1 &= 1x = x\\
    x(y + z) &= xy + xz & (x + y)z &= xz + yz\\
    x0 &= 0x = x & & \\
    1 + aa^* &\leq a^* & 1 + a^*a &\leq a^*\\
     b + ax \leq x &\implies a^*b \leq x &  b + xa \leq x &\implies ba^* \leq x
  \end{align*}
  \label{fig:axioms}
  \caption{Kleene algebra axioms}
\end{figure}

The addition operation can be used to define the partial order
structure $a \leq b$ if $a + b = b$. In the theory of formal languages
this order structure can be used to model language containment. In this
section, we want to categorify the concept of Kleene algebra and
build on top of it in order to define an abstract theory of parsing.
We start by defining \emph{Kleene categories}.

\begin{definition}
  A Kleene category is a distributive monoidal category $\cat{K}$
  such that for every objects $A$ and $B$, the endofunctors $F_{A, B}
  = B + A \otimes X$ and $G_{A, B} = B + X \otimes A$ have initial
  algebras (denoted $\mu X.\, F_{A, B}(X)$) such that $B \otimes (\mu
  X.\, F_{A, 1}) \cong \mu X.\, F_{A, B}(X)$ and the analogue isomorphism
  for $G_{A,B}$ also holds.
\end{definition}

As a sanity check, note that Kleene algebras are indeed examples of
Kleene categories.

\begin{example}
  Every Kleene algebra, seen a posetal category, is a Kleene category.
\end{example}

An unexpected example comes from the theory of substructural logics.

\begin{example}
  The opposite category of every Kleene category is a model of a variant of
  conjunctive ordered logic, where the Kleene star plays the role of the ``of
  course'' modality from substructural logics which allows hypotheses to
  be discarded or duplicated.
\end{example}

\steven{What is the ``of course'' modality? Is this ``$!$'' in linear logic?}

The proposed axioms are a direct translation of the Kleene algebra
axioms to a categorical setting. Its most unusual aspect is the
axiomatization of the Kleene star as a family of initial algebras
satisfying certain isomorphisms. If the Kleene category $\cat{K}$ has
more structure, then these isomorphisms hold ``for free''.

\begin{theorem}
  \label{th:kleeneclosed}
  Let $\cat{K}$ be a Kleene category such that it is also monoidal
  closed.  Then, the initial algebras isomorphisms hold automatically.
\end{theorem}
\begin{proof}
  We prove this by the unicity (up-to isomorphism) of initial
  algebras. Let $[hd, tl]: 1 + (\mu X.\, F_{A, 1}(X)) \otimes A \to
  (\mu X.\, F_{A, 1}(X))$ be the initial algebra structure of $(\mu
  X.\, F_{A, 1}(X))$ and consider the map $[hd, tl] : B + B \otimes
  (\mu X.\, F_{A, 1}(X)) \otimes A \to B\otimes (\mu X.\, F_{A,
    1}(X))$.

  Now, let $[f,g] : B + A \otimes Y \to Y$ be an $F_{A,B}$-algebra and
  we want to show that there is a unique algebra morphism $h : B
  \otimes \mu X.\, F_{A,1} \to Y$. We can show existence and uniqueness
  by showing that the diagram on the left commute if, and only if,
  the diagram on the right commutes:

  This equivalence follows by using the adjunction structure given
  by the monoidal closed structure of $\cat{K}$. A completely analogous
  argument for $G_{A,B}$ also holds.
\end{proof}

This result feels similar in spirit to the definition of action
algebras, which are algebras where the product also has adjoint
operations which results in the Kleene star being more easily
axiomatized \cite{kozen1994}.

We are now ready to prove that our concept of formal grammars fits
nicely within our categorical framework. We start by presenting a
well-known construction from presheaf categories.

\begin{definition}
  Let $\cat{C}$ be a locally small monoidal category and $F$, $G$ be
  two functors $\cat{C} \to \Set$. Their Day convolution tensor
  product is defined as the following coend formula:
  \[
  (F \otimes_{Day} G)(x) = \int^{(y,z) \in \cat{C}\times\cat{C}}\cat{C}(y\otimes z, x) \times F(y) \times G(z) 
  \]
  Dually, its internal hom is given by the following end formula:
  \[
  (F \lto_{Day} G)(x) = \int_{y} \Set(F(y), G(x \otimes y))
  \]
\end{definition}

\begin{lemma}[\cite{day1970}]
  Under the assumptions above, the presheaf category $\Set^{\cat{C}}$ is
  monoidal closed.
\end{lemma}

%% \begin{theorem}
%%   Let $\cat{K}$ be a Kleene category and $A$ a discrete category.
%%   The functor category $[A, \cat{K}]$.
%%   (HOW GENERAL SHOULD THIS THEOREM BE? BY ASSUMING ENOUGH STRUCTURE,
%%   E.G. K = Set, THIS THEOREM BECOMES SIMPLE TO PROVE)
%% \end{theorem}
\begin{theorem}
  If $\cat{C}$ is a locally small monoidal category, then
  $\Set^{\cat{C}}$ is a Kleene category.
\end{theorem}
\begin{proof}

  By the lemma above, $\Set^{\cat{C}}$ is monoidal closed, and since it
  is a presheaf category, it has coproducts. Furthermore, the tensor
  is a left adjoint, i.e. it preserves colimits and, therefore, it is
  a distributive category.

  As for the Kleene star, since presheaf categories admit small colimits,
  the initial algebra of the functors $F_{A,B}$ and $G_{A,B}$ can be
  defined as the filtered colimit of the diagrams:

  From Theorem~\ref{th:kleeneclosed} it follows that these initial
  algebras satisfy the required isomorphisms and this concludes the
  proof.
\end{proof}

\begin{corollary}
  For every alphabet $\Sigma$, the presheaf category $\Set^{\cat{\Sigma^*}}$
  is a Kleene category.
\end{corollary}
\begin{proof}
  Note that string concatenation and the empty string make the
  discrete category $\Sigma^*$ a strict monoidal category.
\end{proof}

Much like in the posetal case, the abstract structure of a 2-Kleene
algebra is expressive enough to synthetically reason about formal
languages. A significant difference between them is that while Kleene
algebras can reason about language containment, 2-Kleene algebras can
reason about parsing as well.

For the rest of the paper we will use the presheaf category
$\Set^{\cat{\Sigma^*}}$ as a concrete model that will serve as our
guide when expanding abstract formalism presented in this section so
that it can handle more classes of languages beyond regular ones.

\section{Related work}

\paragraph{Kleene Algebra}

Since the early works in the theory of formal languages, Kleene
algebras have played an important role in its development. They
generalize the operations known from regular languages by introducing
operations generalizing language composition, language union and the
Kleene star.  More generally, they are defined as inequational theory
where the inequality is meant to capture language containment. This
theory is extremely successful, having found applications in algebraic
path problems, theory of programming languages, compiler optimizations
and more.

A frequently fruitful research direction is exploring varying
extensions of Kleene algebras, Kleene algebra with tests (KAT) being
one of the most notable ones. Our approach is radically different from
most extensions, which usually aim at modifying or adding new
operations to Kleene algebras, but still keeping it as an inequational
theory. By adopting a category-theoretic treatment and allowing the
``order structure'' to encode more information than merely
inequalities, we were able to extend Kleene algebra to reason about
parsing as well.

\paragraph{TODO: more stuff}

%% That paper with Fritz Henglein about regexes as types

%% Vaughan Pratt on the residual operator


\section{Universal Constructions in the Category of Grammars}

Predicate BI: bicartesian closed, monoidal biclosed, omega-colimits
and therefore certain initial algebras



\section{A Bunched Type Theory for Grammars}

\subsection{Syntax}
Judgments: $\Delta$ set ctx, $\Delta \vdash A$ set, $\Delta \vdash M :
A$ term, $\Delta \vdash \Gamma$ grammar ctx, $\Delta \vdash G$
grammar, $\Delta\pipe \Gamma \vdash p : G$ parse term.

\begin{figure}
  \label{fig:structjdg}
  \begin{mathpar}
    \inferrule{~}{\ctxwff \cdot}
    \and
    \inferrule{\ctxwff \Gamma \\ \ctxwffjdg \Gamma X}{\ctxwff {\Gamma, x : X}}
    
    \\

    \inferrule{~}{\linctxwff \Gamma \cdot}
    \and
    \inferrule{\linctxwff \Gamma \Delta \\ \linctxwffjdg \gamma A}{\linctxwff \Gamma {\Delta, x : A}}

    \\

    \inferrule{\Gamma \vdash X : U_i}{\ctxwffjdg \Gamma X}

    \and
    
    \inferrule{\Gamma \vdash A : L_i}{\linctxwffjdg \Gamma A}

    \\

    \inferrule{\Gamma \vdash X \equiv Y : U_i}{\ctxwffjdg \Gamma {X\equiv Y}}

    \and
    
    \inferrule{\Gamma \vdash A \equiv B : L_i}{\linctxwffjdg \Gamma {A \equiv B}}

  \end{mathpar}
  \caption{Structural judgements}
\end{figure}

\begin{figure}
  \label{fig:typewf}
  \begin{mathpar}
    \inferrule{~}{\Gamma \vdash U_i : U_{i+1}}
 %   
    \and
%
    \inferrule{~}{\Gamma \vdash L_i : U_{i+1}}
%
    \\
%
    \inferrule{\Gamma \vdash X : U_i \\ \hspace{-0.1cm} \Gamma, x : X \vdash Y : U_i}{\Gamma \vdash \PiTy x X Y : U_i }%
%
    \and
%
    \inferrule{\Gamma\vdash X : U_i \\ \hspace{-0.1cm} \Gamma, x : X \vdash Y : U_i}{\Gamma \vdash \SigTy x X Y : U_i}
%
    \\
%
    \inferrule{~}{\Gamma \vdash 1 : U_i}
%
    \and
%
    \inferrule{\Gamma \vdash A : L_i}{\Gamma \vdash G A : U_i}
%
    \\
%
    \inferrule{~}{\Gamma \vdash I : L_i}
 %   
    \and
%
    \inferrule{\Gamma \vdash A : L_i \\ \hspace{-0.1cm}\Gamma \vdash B : L_i}{\Gamma \vdash A \otimes B : L_i}
%
    \and
%
    \inferrule{\Gamma \vdash A : L_i \\ \hspace{-0.1cm}\Gamma \vdash B : L_i}{\Gamma \vdash A \lto B : L_i}
%
    \\
%
    \inferrule{\Gamma \vdash X : U_i \\ \Gamma, x : X \vdash A : L_i}{\Gamma \vdash \LinPiTy x X A : L_i}
%
    \and
%
    \inferrule{\Gamma \vdash X : U_i \\ \Gamma, x : X \vdash A : L_i}{\Gamma \vdash \LinSigTy x X A : L_i}
%
    \\
%
    \inferrule{~}{\Gamma \vdash \top : L_i}
%
    \and
%
    \inferrule{\Gamma \vdash A : L_i \\ \Gamma \vdash B : L_i}{\Gamma \vdash A \amp B : L_i}
%
    \\
%
    \inferrule{~}{\Gamma \vdash \GrTy : L_1}
%
    \and
%
    \mprset { fraction ={===}}
    \inferrule{\Gamma \vdash X : L_1}{\Gamma \vdash : \GrTy}
%
    \and
%
    \mprset { fraction ={---}}
    \inferrule{\Gamma, x : \GrTy \vdash A : L_i}{\Gamma \vdash \mu x.\, A : L_i}
  \end{mathpar}
  \caption{Type well-formedness}
\end{figure}

\begin{figure}
  \label{fig:inttyping}
  \begin{mathpar}
  \inferrule{~}{\Gamma, x : X, \Gamma' \vdash x : X}
  %
  \and
  %
  \inferrule{\Gamma \vdash e : Y \quad \ctxwffjdg \Gamma {X \equiv Y}}{\Gamma \vdash e : X}
  %
  \and
  %
  \inferrule{~}{\Gamma \vdash () : 1}
  %
  \\
  %
  \inferrule{\Gamma \vdash e : X \\ \Gamma \vdash e; : \subst Y e x}{\Gamma \vdash (e, e') : \SigTy x X Y}
  %
  \and
%
  \inferrule{\Gamma \vdash e : \SigTy x X Y}{\Gamma \vdash \pi_1\, e : X}
  %
  \\
  %
  \inferrule{\Gamma \vdash e : \SigTy x X Y}{\Gamma \vdash \pi_2\, e : \subst Y {\pi_1\, e} x}
  \and
  \inferrule{\ctxwffjdg \Gamma {\PiTy x X Y} \\ \Gamma, x : X \vdash e : Y}{\Gamma \vdash \lamb x e : \PiTy x X Y}
  %
  \\
  %
  \inferrule{\Gamma \vdash e : \PiTy x X Y \\ \Gamma \vdash e' : X}{\Gamma \vdash \app e {e'} : \subst Y {e'} x}
  %
  \\
  %
  \inferrule{\Gamma \vdash e \equiv e' : X}{\Gamma \vdash \mathsf{refl} : e =_X e'}
  \and
  \inferrule{\Gamma \mid \cdot \vdash e : A}{\Gamma \vdash \mathsf G e : \mathsf G A}
  \end{mathpar}
  \caption{Intuitionistic typing}
\end{figure}

\begin{figure}
  \label{fig:linsyntax}
  \begin{mathpar}
    \inferrule{~}{\Gamma \mid a : A \vdash a : A}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : B \\ \linctxwffjdg \Gamma {A \equiv B}}{\Gamma \mid \Delta \vdash e : A}
    %
    \\
    %
    \inferrule{~}{\Gamma \mid \cdot \vdash () : I}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : I \\ \Gamma \mid \Delta' \vdash e' : C}{\Gamma \mid \Delta,\Delta' \vdash \letin {()} e {e'} : C}
    %
    \\
    %
    \inferrule{\Gamma \mid \Delta \vdash e : A \\ \Gamma \mid \Delta' \vdash e' : B}{\Gamma \mid \Delta, \Delta' \vdash e \otimes e' : A \otimes B}
    %
    \\
    %
    \inferrule{\Gamma \mid \Delta \vdash e : A \otimes B \\ \Gamma \mid \Delta'_1, a : A, b : B, \Delta'_2 \vdash e'}{\Gamma \mid  \Delta_1', \Delta, \Delta'_2 \vdash \letin {a \otimes b} e {e'}}
    \\
    %
    \inferrule{\Gamma \mid \Delta, a : A \vdash e : B}{\Gamma \mid \Delta \vdash \lamb a e : A\lto B}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : A \lto B \\ \Gamma \mid \Delta' \vdash e' : A}{\Gamma \mid \Delta, \Delta' \vdash \app e {e'} : A}
    \\
    %
    \inferrule{\Gamma \mid a : A, \Delta \vdash e : B}{\Gamma \mid \Delta \vdash \lamb a e : A\tol B}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : A \tol B \\ \Gamma \mid \Delta' \vdash e' : A}{\Gamma \mid \Delta, \Delta' \vdash \app e {e'} : A}
    %
    \\
    %
    \inferrule{\Gamma, x : X \mid \Delta  \vdash e : A}{\Gamma \mid \Delta \vdash \dlamb x e : \LinPiTy x X A}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : \LinPiTy x X A \\ \Gamma \vdash e' : X}{\Gamma \mid \Delta \vdash \app e {e'} : \subst A {e'} x}
    %
    \\
    %
    \inferrule{~}{\Gamma \mid \Delta \vdash () : \top}
    %
    \\
    %
    \inferrule{\Gamma \mid \Delta \vdash e_1 : A_1 \quad \Gamma \mid \delta \vdash e_2 : A_2}{\Gamma \mid \Delta \vdash (e_1, e_2) : A_1 \amp A_2}
    \and
    \inferrule{\Gamma \mid \Delta \vdash e : A_1 \amp A_2 }{\Gamma \mid \Delta \vdash \pi_i \, e : A_i}
    %
    \\
    %
    \inferrule{\Gamma \vdash e : X \quad \Gamma \mid \Delta \vdash e' : \subst A e x}{\Gamma \mid \Delta \vdash (e, e') : \LinSigTy x X A}
    %
    \\
    %
    \inferrule{\Gamma \mid \Delta \vdash e : \LinSigTy x X A \quad \Gamma, x : X \mid \Delta'_1, a : A, \Delta'_2 \vdash e' : C}{\Gamma\mid \Delta'_1, \Delta, \Delta'_2 \vdash \letin {(x, a)} e {e'}: C}
    %
    \\
    %
    \inferrule{\Gamma \vdash e : \mathsf{G} A}{\Gamma \mid \cdot \vdash \mathsf{G}^{-1}\, e : A}
    %
    \\
    %
    \inferrule{~}{\Gamma\mid \cdot \vdash \varepsilon : \GrTy}
    \and
    \inferrule{\sigma \in \Sigma}{\Gamma \mid \cdot \vdash \sigma : \GrTy}
    %
    \\
    %
    \inferrule{~}{\Gamma; \Delta \vdash \mathsf{fold}\, t : \mu X.\, A}
    \and
    \inferrule{~}{\Gamma; \Delta \vdash \mathsf{unfold}\, t : \mu X.\, A}
  \end{mathpar}
  \caption{Linear typing}
\end{figure}

\pedro{Need to figure out the rules for inductive types and write down
the judgemental equality rules}
\subsection{Semantics}

Propositional fragment: monoidal biclosed category that is also
bicartesian closed and has $\omega$-colimits. Call such a BIC.

Set theoretic fragment: category with families $\mathcal C$ + $\Pi,\Sigma,W$.

Combination: category with families $\mathcal C$ + a functor $L : C
\to \textrm{BIC}$.

Grammatical fragment: functor from $\mathcal C$ to the category of BI-models

Example: use $\Set$ as the CwF, use the functor $\Delta \mapsto
(\Set^{\Sigma^*})^\Delta$ as the model of the propositional fragment
using the pointwise-Day convolution monoidal structure.

\subsection{Canonicity}

Let $\cdot \vdash G$ be a grammar. Then there are
two obvious notions of what constitutes a ``parse'' of a string w
according to the grammar $G$:
\begin{enumerate}
\item On the one hand we have the semantics just defined, $\llbracket G \rrbracket w$
\item On the other hand, we can view the string $w$ as a grammar
  $\lceil w \rceil$ and define a parse to be a parse terms $\cdot\pipe
  x:\lceil w \rceil \vdash p : G$ modulo $\beta\eta$ equivalence.
\end{enumerate}

It is not difficult to see that at least for the ``strictly positive''
formulae (those featuring only the positive connectives
$0,+,\epsilon,\otimes,\mu$ and the generators $c$) that every element
$t \in \llbracket G \rrbracket w$ is a kind of tree and that the nodes
of the tree correspond precisely to the introduction forms of the
type. However it is far less obvious that \emph{every} proof $x:\lceil
w \rceil \vdash p : \phi$ is equal to some sequence of introduction
forms since proofs can include elimination forms as well. To show that
this is indeed the case we give a \emph{canonicity} result for the
calculus, a generalization of the disjunction theorem of constructive
logic:
\begin{enumerate}
\item Every term $\lceil w \rceil \vdash p : G + H$ is equal to $\sigma_1q$ or $\sigma_2 r$ (but not both)
\item There are no terms $\lceil w \rceil \vdash p : 0$
\item If there is a term $\lceil w \rceil \vdash p : c$ then $w = c$ and $p = x$.
\item Every term $\lceil w \rceil \vdash p : G \otimes H$ is equal to $(q,r)$ for some $q,r$
\item Every term $\lceil w \rceil \vdash p : \epsilon$ is equal to $()$
\item Every term $\lceil w \rceil \vdash p : c$ is equal to $x:c$
\item Every term $\lceil w \rceil \vdash p : \mu X. G$ is equal to $\textrm{roll}(q)$ where $q : G(\mu X.G/X)$
\item Every term $\lceil w \rceil \vdash p : (x:A) \times G$ is equal
  to $(M,q)$ where $\cdot \vdash M : A$
\end{enumerate}

To prove this result we will use a logical families construction by
constructing a second model. First, the category with families will be
the category of logical families over set contexts/types
$\Delta$/$A$. Then the propositional portion will be defined by
mapping a logical family $\hat \Gamma \to \Gamma$ 

First, let $L$ be the category of BI formulae and proofs (quotiented
by $\beta\eta$ equality). Define a functor $N : L \to \Set^{\Sigma^*}$ by
\[ N(\phi)(w) = L(w,\phi) \]

Then define the gluing category $\mathcal G$ as the comma category
$\Set^{\Sigma^*}/N$. That is, an object of this category is a pair of
a formula $\phi \in L$ and an object $S \in \mathcal
P(\Sigma^*)/N(\phi)$. We can then use the equivalence $\mathcal
P(\Sigma^*)/N(\phi) \cong \mathcal P(\int N(\phi))$ to get a simple
description of such an $S$: it is simply a family of sets indexed by
proofs $L(w,\phi)$:
\[ \prod_{w\in\Sigma^*} L(w,\phi) \to \Set \]
This category clearly comes with a projection functor $\pi : \mathcal
G \to \mathcal L$ and then our goal is to define a section by using
the universal property of $\mathcal L$.

To this end we define
\pedro{I'm pretty sure that these definitions have been somewhat presented
  in ``Glueing and orthogonality for models of linear logic'' by Hyland and Schalk.
We should probably cite them so that we don't have to rederive their constructions and proofs here.}
\begin{enumerate}
\item $(\phi, S) \otimes (\psi, T) = (\phi \otimes \psi, S\otimes T)$ where
  \[ (S \otimes T)(w, p) = (w_1w_2 = w) \times (q_1,q_2 = p) \times S\,w_1\,q_1 \times T\,w_2\,q_2\]
\item $(\phi, S) \multimap (\psi, T) = (\phi \multimap \psi, S \multimap T)$ where
  \[ (S \multimap T)(w,p) = w' \to q \to S\,w'\,q \to T (ww') (p\,q) \]
\item $\mu X. ??$ ??
\end{enumerate}

\section{Logical Characterizations of Language Classes}

Our bunched type theory 

Predicate BI with existential quantifiers is already enough to define
formulae that correspond to arbitrary recursively enumerable languages
since we can simulate the tape of a Turing machine using two
stacks. I.e., we can define a set $S$ of lists of tape symbols, and
then define a formula that first ``copies'' the input onto one stack, then executes

\[ \mu \textrm{Copy} : S \to *. \lambda s. (\epsilon \wedge T\,s\,[])\bigvee_{c \in \Sigma} c (S\,{c::s}) \]



\section{Future work}

\subsection{Beyond Strings}

While parsing typically refers to the production of semantic objects
from their description as strings, many tasks in programming can be
viewed as parsing of more structured objects such as trees, trees with
binding structure or graphs. Fundamental to programming language
implementation is \emph{type checking}, analogous to language
recognition, or more generally \emph{typed elaboration}, analogous to
parsing, which produces a semantic object in addition to performing
some analysis. A type system could then be interpreted as a \emph{tree
grammar}. Our definition of string grammars as functors from
$\Sigma^*$ to $\Set$ can then be easily adapted to functors to $\Set$
from the set of \emph{trees} freely generated form some signature of
nodes. Then just as the set of string grammars inherits a monoidal
structure from the free monoid of strings using the Day convolution,
this set of tree grammars inherits a kind of weak algebraic structure
corresponding to the tree constructors. This suggests an even more
unusual form of bunched type theory, where the monoidal concatenation
and unit are replaced with context constructors corresponding to the
tree constructors.

\end{document}
