
@inproceedings{lautemann_logics_1995,
	address = {Berlin, Heidelberg},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Logics for context-free languages},
	isbn = {978-3-540-49404-1},
	doi = {10.1007/BFb0022257},
	abstract = {We define matchings, and show that they capture the essence of context-freeness. More precisely, we show that the class of context-free languages coincides with the class of those sets of strings which can be defined by sentences of the form ∃ bϕ, where ϕ is first order, b is a binary predicate symbol, and the range of the second order quantifier is restricted to the class of matchings. Several variations and extensions are discussed.},
	language = {en},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer},
	author = {Lautemann, Clemens and Schwentick, Thomas and Thérien, Denis},
	editor = {Pacholski, Leszek and Tiuryn, Jerzy},
	year = {1995},
	pages = {205--216},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/K8WPLXLQ/Lautemann et al. - 1995 - Logics for context-free languages.pdf:application/pdf},
}

@article{henglein_regular_2011,
	title = {Regular expression containment: coinductive axiomatization and computational interpretation},
	volume = {46},
	issn = {0362-1340},
	shorttitle = {Regular expression containment},
	url = {https://dl.acm.org/doi/10.1145/1925844.1926429},
	doi = {10.1145/1925844.1926429},
	abstract = {We present a new sound and complete axiomatization of regular expression containment. It consists of the conventional axiomatization of concatenation, alternation, empty set and (the singleton set containing) the empty string as an idempotent semiring, the fixed- point rule E* = 1 + E × E* for Kleene-star, and a general coinduction rule as the only additional rule. Our axiomatization gives rise to a natural computational interpretation of regular expressions as simple types that represent parse trees, and of containment proofs as coercions. This gives the axiom- atization a Curry-Howard-style constructive interpretation: Containment proofs do not only certify a language-theoretic contain- ment, but, under our computational interpretation, constructively transform a membership proof of a string in one regular expression into a membership proof of the same string in another regular expression. We show how to encode regular expression equivalence proofs in Salomaa's, Kozen's and Grabmayer's axiomatizations into our containment system, which equips their axiomatizations with a computational interpretation and implies completeness of our axiomatization. To ensure its soundness, we require that the computational interpretation of the coinduction rule be a hereditarily total function. Hereditary totality can be considered the mother of syn- tactic side conditions: it "explains" their soundness, yet cannot be used as a conventional side condition in its own right since it turns out to be undecidable. We discuss application of regular expressions as types to bit coding of strings and hint at other applications to the wide-spread use of regular expressions for substring matching, where classical automata-theoretic techniques are a priori inapplicable. Neither regular expressions as types nor subtyping interpreted coercively are novel per se. Somewhat surprisingly, this seems to be the first investigation of a general proof-theoretic framework for the latter in the context of the former, however.},
	number = {1},
	urldate = {2023-11-28},
	journal = {ACM SIGPLAN Notices},
	author = {Henglein, Fritz and Nielsen, Lasse},
	month = jan,
	year = {2011},
	keywords = {axiomatization, coercion, coinduction, computational interpretation, containment, equivalence, regular expression, type},
	pages = {385--398},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/ZUZHNIP8/Henglein and Nielsen - 2011 - Regular expression containment coinductive axioma.pdf:application/pdf},
}

@article{grathwohl_infinitary_2013,
	title = {Infinitary {Axiomatization} of the {Equational} {Theory} of {Context}-{Free} {Languages}},
	volume = {126},
	issn = {2075-2180},
	url = {http://arxiv.org/abs/1309.0893},
	doi = {10.4204/EPTCS.126.4},
	abstract = {We give a natural complete infinitary axiomatization of the equational theory of the context-free languages, answering a question of Lei\{{\textbackslash}ss\} (1992).},
	urldate = {2023-11-28},
	journal = {Electronic Proceedings in Theoretical Computer Science},
	author = {Grathwohl, Niels Bjørn Bugge and Henglein, Fritz and Kozen, Dexter},
	month = aug,
	year = {2013},
	note = {arXiv:1309.0893 [cs]},
	keywords = {Computer Science - Formal Languages and Automata Theory, Computer Science - Logic in Computer Science},
	pages = {44--55},
	file = {arXiv Fulltext PDF:/Users/stevenschaefer/Zotero/storage/TJHAX5RI/Grathwohl et al. - 2013 - Infinitary Axiomatization of the Equational Theory.pdf:application/pdf;arXiv.org Snapshot:/Users/stevenschaefer/Zotero/storage/INYKMZZH/1309.html:text/html},
}

@inproceedings{krishnaswami_integrating_2015,
	address = {Mumbai India},
	title = {Integrating {Linear} and {Dependent} {Types}},
	isbn = {978-1-4503-3300-9},
	url = {https://dl.acm.org/doi/10.1145/2676726.2676969},
	doi = {10.1145/2676726.2676969},
	abstract = {In this paper, we show how to integrate linear types with type dependency, by extending the linear/non-linear calculus of Benton to support type dependency.},
	language = {en},
	urldate = {2024-01-04},
	booktitle = {Proceedings of the 42nd {Annual} {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Krishnaswami, Neelakantan R. and Pradic, Pierre and Benton, Nick},
	month = jan,
	year = {2015},
	pages = {17--30},
	file = {Krishnaswami et al. - 2015 - Integrating Linear and Dependent Types.pdf:/Users/stevenschaefer/Zotero/storage/867QYE2N/Krishnaswami et al. - 2015 - Integrating Linear and Dependent Types.pdf:application/pdf},
}

@article{hyland_glueing_2003,
	title = {Glueing and orthogonality for models of linear logic},
	volume = {294},
	issn = {03043975},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0304397501002419},
	doi = {10.1016/S0304-3975(01)00241-9},
	abstract = {We present the general theory of the method of glueing and associated technique of orthogonality for constructing categorical models of all the structure of linear logic: in particular we treat the exponentials in detail. We indicate simple applications of the methods and show that they cover familiar examples. c 2002 Elsevier Science B.V. All rights reserved.},
	language = {en},
	number = {1-2},
	urldate = {2024-03-04},
	journal = {Theoretical Computer Science},
	author = {Hyland, Martin and Schalk, Andrea},
	month = feb,
	year = {2003},
	pages = {183--231},
	file = {Hyland and Schalk - 2003 - Glueing and orthogonality for models of linear log.pdf:/Users/stevenschaefer/Zotero/storage/EZ43SYGH/Hyland and Schalk - 2003 - Glueing and orthogonality for models of linear log.pdf:application/pdf},
}

@inproceedings{krishnaswami_typed_2019,
	address = {Phoenix AZ USA},
	title = {A typed, algebraic approach to parsing},
	isbn = {978-1-4503-6712-7},
	url = {https://dl.acm.org/doi/10.1145/3314221.3314625},
	doi = {10.1145/3314221.3314625},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Proceedings of the 40th {ACM} {SIGPLAN} {Conference} on {Programming} {Language} {Design} and {Implementation}},
	publisher = {ACM},
	author = {Krishnaswami, Neelakantan R. and Yallop, Jeremy},
	month = jun,
	year = {2019},
	pages = {379--393},
	file = {Krishnaswami and Yallop - 2019 - A typed, algebraic approach to parsing.pdf:/Users/stevenschaefer/Zotero/storage/HUS3NZFK/Krishnaswami and Yallop - 2019 - A typed, algebraic approach to parsing.pdf:application/pdf},
}

@article{leroy_formal_2009,
	title = {Formal verification of a realistic compiler},
	volume = {52},
	issn = {0001-0782, 1557-7317},
	url = {https://dl.acm.org/doi/10.1145/1538788.1538814},
	doi = {10.1145/1538788.1538814},
	abstract = {This paper reports on the development and formal verification (proof of semantic preservation) of CompCert, a compiler from Clight (a large subset of the C programming language) to PowerPC assembly code, using the Coq proof assistant both for programming the compiler and for proving its correctness. Such a verified compiler is useful in the context of critical software and its formal verification: the verification of the compiler guarantees that the safety properties proved on the source code hold for the executable compiled code as well.},
	language = {en},
	number = {7},
	urldate = {2024-04-22},
	journal = {Communications of the ACM},
	author = {Leroy, Xavier},
	month = jul,
	year = {2009},
	pages = {107--115},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/UW7FUAX2/Leroy - 2009 - Formal verification of a realistic compiler.pdf:application/pdf},
}

@inproceedings{kumar_cakeml_2014,
	address = {San Diego California USA},
	title = {{CakeML}: a verified implementation of {ML}},
	isbn = {978-1-4503-2544-8},
	shorttitle = {{CakeML}},
	url = {https://dl.acm.org/doi/10.1145/2535838.2535841},
	doi = {10.1145/2535838.2535841},
	abstract = {We have developed and mechanically veriﬁed an ML system called CakeML, which supports a substantial subset of Standard ML. CakeML is implemented as an interactive read-eval-print loop (REPL) in x86-64 machine code. Our correctness theorem ensures that this REPL implementation prints only those results permitted by the semantics of CakeML. Our veriﬁcation effort touches on a breadth of topics including lexing, parsing, type checking, incremental and dynamic compilation, garbage collection, arbitraryprecision arithmetic, and compiler bootstrapping.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Proceedings of the 41st {ACM} {SIGPLAN}-{SIGACT} {Symposium} on {Principles} of {Programming} {Languages}},
	publisher = {ACM},
	author = {Kumar, Ramana and Myreen, Magnus O. and Norrish, Michael and Owens, Scott},
	month = jan,
	year = {2014},
	pages = {179--191},
	file = {Kumar et al. - 2014 - CakeML a verified implementation of ML.pdf:/Users/stevenschaefer/Zotero/storage/L2QPEHF2/Kumar et al. - 2014 - CakeML a verified implementation of ML.pdf:application/pdf},
}


@article{yangFindingUnderstandingBugs,
	title = {Finding and {Understanding} {Bugs} in {C} {Compilers}},
	abstract = {Compilers should be correct. To improve the quality of C compilers, we created Csmith, a randomized test-case generation tool, and spent three years using it to ﬁnd compiler bugs. During this period we reported more than 325 previously unknown bugs to compiler developers. Every compiler we tested was found to crash and also to silently generate wrong code when presented with valid input. In this paper we present our compiler-testing tool and the results of our bug-hunting study. Our ﬁrst contribution is to advance the state of the art in compiler testing. Unlike previous tools, Csmith generates programs that cover a large subset of C while avoiding the undeﬁned and unspeciﬁed behaviors that would destroy its ability to automatically ﬁnd wrong-code bugs. Our second contribution is a collection of qualitative and quantitative results about the bugs we have found in open-source C compilers.},
	language = {en},
	author = {Yang, Xuejun and Chen, Yang and Eide, Eric and Regehr, John},
	file = {Yang et al. - Finding and Understanding Bugs in C Compilers.pdf:/Users/stevenschaefer/Zotero/storage/6ZSM5RDR/Yang et al. - Finding and Understanding Bugs in C Compilers.pdf:application/pdf},
}

@incollection{jourdanValidatingLRParsers2012,
	address = {Berlin, Heidelberg},
	title = {Validating {LR}(1) {Parsers}},
	volume = {7211},
	isbn = {978-3-642-28868-5 978-3-642-28869-2},
	url = {http://link.springer.com/10.1007/978-3-642-28869-2_20},
	abstract = {An LR(1) parser is a ﬁnite-state automaton, equipped with a stack, which uses a combination of its current state and one lookahead symbol in order to determine which action to perform next. We present a validator which, when applied to a context-free grammar G and an automaton A, checks that A and G agree. Validating the parser provides the correctness guarantees required by veriﬁed compilers and other high-assurance software that involves parsing. The validation process is independent of which technique was used to construct A. The validator is implemented and proved correct using the Coq proof assistant. As an application, we build a formally-veriﬁed parser for the C99 language.},
	language = {en},
	urldate = {2024-04-22},
	booktitle = {Programming {Languages} and {Systems}},
	publisher = {Springer Berlin Heidelberg},
	author = {Jourdan, Jacques-Henri and Pottier, François and Leroy, Xavier},
	editor = {Hutchison, David and Kanade, Takeo and Kittler, Josef and Kleinberg, Jon M. and Mattern, Friedemann and Mitchell, John C. and Naor, Moni and Nierstrasz, Oscar and Pandu Rangan, C. and Steffen, Bernhard and Sudan, Madhu and Terzopoulos, Demetri and Tygar, Doug and Vardi, Moshe Y. and Weikum, Gerhard and Seidl, Helmut},
	year = {2012},
	doi = {10.1007/978-3-642-28869-2_20},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {397--416},
	file = {Jourdan et al. - 2012 - Validating LR(1) Parsers.pdf:/Users/stevenschaefer/Zotero/storage/UJQGN33D/Jourdan et al. - 2012 - Validating LR(1) Parsers.pdf:application/pdf},
}

@incollection{bentonMixedLinearNonlinear1995,
	address = {Berlin, Heidelberg},
	title = {A mixed linear and non-linear logic: {Proofs}, terms and models: {Extended} abstract},
	volume = {933},
	isbn = {978-3-540-60017-6 978-3-540-49404-1},
	shorttitle = {A mixed linear and non-linear logic},
	url = {http://link.springer.com/10.1007/BFb0022251},
	abstract = {Intuitionistic linear logic regains the expressive power of intuitionistic logic through the ! ('of course') modality. Benton, Bierman, Hyland and de Paiva have given a term assignment system for ILL and an associated notion of categorical model in which the ! modality is modelled by a comonad satisfying certain extra conditions. Ordinary intuitionistic logic is then modelled in a cartesian dosed category which arises as a full subcategory of the category of coalgebras for the comonad. This paper attempts to explain the connection between ILL and IL more directly and symmetricallyby giving a logic, term calculus and categorical model for a system in which the linear and non-linear worlds exist on an equal footing, with operations allowing one to pass in both directions. We start from the categorical model of ILL given by Benton, Bierman, Hyland and de Paiva and show that this is equivalent to having a symmetric monoidal adjunction between a symmetric monoidal dosed category and a cartesian closed category. We then derive both a sequent calculus and a natural deduction presentation of the logic corresponding to the new notion of model.},
	language = {en},
	urldate = {2024-04-27},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer Berlin Heidelberg},
	author = {Benton, P. N.},
	editor = {Goos, Gerhard and Hartmanis, Juris and Van Leeuwen, Jan and Pacholski, Leszek and Tiuryn, Jerzy},
	year = {1995},
	doi = {10.1007/BFb0022251},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {121--135},
	file = {BFb0022251.pdf:/Users/stevenschaefer/Downloads/BFb0022251.pdf:application/pdf},
}

@article{brzozowskiDerivativesRegularExpressions1964,
	title = {Derivatives of {Regular} {Expressions}},
	volume = {11},
	issn = {0004-5411, 1557-735X},
	url = {https://dl.acm.org/doi/10.1145/321239.321249},
	doi = {10.1145/321239.321249},
	language = {en},
	number = {4},
	urldate = {2024-04-29},
	journal = {Journal of the ACM},
	author = {Brzozowski, Janusz A.},
	month = oct,
	year = {1964},
	pages = {481--494},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/CMQXUWQR/Brzozowski - 1964 - Derivatives of Regular Expressions.pdf:application/pdf},
}

@inproceedings{mightParsingDerivativesFunctional2011,
	address = {Tokyo Japan},
	title = {Parsing with derivatives: a functional pearl},
	isbn = {978-1-4503-0865-6},
	shorttitle = {Parsing with derivatives},
	url = {https://dl.acm.org/doi/10.1145/2034773.2034801},
	doi = {10.1145/2034773.2034801},
	language = {en},
	urldate = {2024-04-29},
	booktitle = {Proceedings of the 16th {ACM} {SIGPLAN} international conference on {Functional} programming},
	publisher = {ACM},
	author = {Might, Matthew and Darais, David and Spiewak, Daniel},
	month = sep,
	year = {2011},
	pages = {189--195},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/Y99XZYVR/Might et al. - 2011 - Parsing with derivatives a functional pearl.pdf:application/pdf},
}

@article{rabinFiniteAutomataTheir1959,
	title = {Finite {Automata} and {Their} {Decision} {Problems}},
	volume = {3},
	issn = {0018-8646, 0018-8646},
	url = {http://ieeexplore.ieee.org/document/5392601/},
	doi = {10.1147/rd.32.0114},
	abstract = {Finite automata are considered in this paper as instruments for classifying finite tapes. Each onetape automaton defines a set of tapes, a two-tape automaton defines a set of pairs of tapes, et cetera. The structure of the defined sets is studied. Various generalizations of the notion of an automaton are introduced and their relation to the classical automata is determined. Some decision problems concerning automata are shown to be solvable by effective algorithms; others turn out to be unsolvable by algorithms.},
	language = {en},
	number = {2},
	urldate = {2024-04-29},
	journal = {IBM Journal of Research and Development},
	author = {Rabin, M. O. and Scott, D.},
	month = apr,
	year = {1959},
	pages = {114--125},
	file = {Rabin and Scott - 1959 - Finite Automata and Their Decision Problems.pdf:/Users/stevenschaefer/Zotero/storage/V4PSR9SW/Rabin and Scott - 1959 - Finite Automata and Their Decision Problems.pdf:application/pdf},
}


@article{owensRegularexpressionDerivativesReexamined2009,
	title = {Regular-expression derivatives re-examined},
	volume = {19},
	copyright = {https://www.cambridge.org/core/terms},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/product/identifier/S0956796808007090/type/journal_article},
	doi = {10.1017/S0956796808007090},
	abstract = {Abstract
            Regular-expression derivatives are an old, but elegant, technique for compiling regular expressions to deterministic finite-state machines. It easily supports extending the regular-expression operators with boolean operations, such as intersection and complement. Unfortunately, this technique has been lost in the sands of time and few computer scientists are aware of it. In this paper, we reexamine regular-expression derivatives and report on our experiences in the context of two different functional-language implementations. The basic implementation is simple and we show how to extend it to handle large character sets (e.g., Unicode). We also show that the derivatives approach leads to smaller state machines than the traditional algorithm given by McNaughton and Yamada.},
	language = {en},
	number = {2},
	urldate = {2024-04-29},
	journal = {Journal of Functional Programming},
	author = {Owens, Scott and Reppy, John and Turon, Aaron},
	month = mar,
	year = {2009},
	pages = {173--190},
	file = {Owens et al. - 2009 - Regular-expression derivatives re-examined.pdf:/Users/stevenschaefer/Zotero/storage/PQB9TTVL/Owens et al. - 2009 - Regular-expression derivatives re-examined.pdf:application/pdf},
}


@article{thompsonProgrammingTechniquesRegular1968,
	title = {Programming {Techniques}: {Regular} expression search algorithm},
	volume = {11},
	issn = {0001-0782, 1557-7317},
	shorttitle = {Programming {Techniques}},
	url = {https://dl.acm.org/doi/10.1145/363347.363387},
	doi = {10.1145/363347.363387},
	abstract = {A method for locating specific character strings embedded in character text is described and an implementation of this method in the form of a compiler is discussed. The compiler accepts a regular expression as source language and produces an IBM 7094 program as object language. The object program then accepts the text to be searched as input and produces a signal every time an embedded string in the text matches the given regular expression. Examples, problems, and solutions are also presented.},
	language = {en},
	number = {6},
	urldate = {2024-04-29},
	journal = {Communications of the ACM},
	author = {Thompson, Ken},
	month = jun,
	year = {1968},
	pages = {419--422},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/6FRSL8GN/Thompson - 1968 - Programming Techniques Regular expression search .pdf:application/pdf},
}


@incollection{Bekić1984,
	address = {Berlin, Heidelberg},
	title = {Definable operations in general algebras, and the theory of automata and flowcharts},
	isbn = {978-3-540-38933-0},
	url = {https://doi.org/10.1007/BFb0048939},
	abstract = {We study the class of operations definable from the given operations of an algebra of sets by union, composition, and fixed points; we obtain two theorems on definable operations that give us as special case the regular-equals-recognisable theorem of generalised finite automata theory. Definable operations arise also as the operations computable by charts; by translating into predicate logic, we obtain Manna's formulas for termination and correctness of flowcharts.},
	booktitle = {Programming languages and their definition: {H}. {Bekič} (1936–1982)},
	publisher = {Springer Berlin Heidelberg},
	author = {Bekić, Hans},
	editor = {Jones, C. B.},
	year = {1984},
	doi = {10.1007/BFb0048939},
	pages = {30--55},
}


@article{zhangIntervalParsingGrammars2023,
	title = {Interval {Parsing} {Grammars} for {File} {Format} {Parsing}},
	volume = {7},
	issn = {2475-1421},
	url = {https://dl.acm.org/doi/10.1145/3591264},
	doi = {10.1145/3591264},
	abstract = {File formats specify how data is encoded for persistent storage. They cannot be formalized as context-free grammars since their specifications include context-sensitive patterns such as the random access pattern and the type-length-value pattern. We propose a new grammar mechanism called Interval Parsing Grammars IPGs) for file format specifications. An IPG attaches to every nonterminal/terminal an interval, which specifies the range of input the nonterminal/terminal consumes. By connecting intervals and attributes, the context-sensitive patterns in file formats can be well handled. In this paper, we formalize IPGs' syntax as well as its semantics, and its semantics naturally leads to a parser generator that generates a recursive-descent parser from an IPG. In general, IPGs are declarative, modular, and enable termination checking. We have used IPGs to specify a number of file formats including ZIP, ELF, GIF, PE, and part of PDF; we have also evaluated the performance of the generated parsers.},
	language = {en},
	number = {PLDI},
	urldate = {2024-04-29},
	journal = {Proceedings of the ACM on Programming Languages},
	author = {Zhang, Jialun and Morrisett, Greg and Tan, Gang},
	month = jun,
	year = {2023},
	pages = {1073--1095},
	file = {Full Text PDF:/Users/stevenschaefer/Zotero/storage/4JNN3FNZ/Zhang et al. - 2023 - Interval Parsing Grammars for File Format Parsing.pdf:application/pdf},
}

@article{chom1963,
  title        = {Formal Properties of Grammars},
  author       = {Noam Chomsky},
  year         = 1963,
  journal      = {Handbook of Mathematical Psychology},
  volume       = {II},
  pages        = {323--418},
}

@ARTICLE{chomThreeModels1956 ,
  author={Chomsky, N.},
  journal={IRE Transactions on Information Theory},
  title={Three models for the description of language},
  year={1956},
  volume={2},
  number={3},
  pages={113-124},
  keywords={Natural languages;Testing;Laboratories;Markov processes;Impedance matching;Kernel;Research and development},
  doi={10.1109/TIT.1956.1056813}}

@article{KNUTH1965607,
title = {On the translation of languages from left to right},
journal = {Information and Control},
volume = {8},
number = {6},
pages = {607-639},
year = {1965},
issn = {0019-9958},
doi = {https://doi.org/10.1016/S0019-9958(65)90426-2},
url = {https://www.sciencedirect.com/science/article/pii/S0019995865904262},
author = {Donald E. Knuth},
abstract = {There has been much recent interest in languages whose grammar is sufficiently simple that an efficient left-to-right parsing algorithm can be mechanically produced from the grammar. In this paper, we define LR(k) grammars, which are perhaps the most general ones of this type, and they provide the basis for understanding all of the special tricks which have been used in the construction of parsing algorithms for languages with simple structure, e.g. algebraic languages. We give algorithms for deciding if a given grammar satisfies the LR(k) condition, for given k, and also give methods for generating recognizes for LR(k) grammars. It is shown that the problem of whether or not a grammar is LR(k) for some k is undecidable, and the paper concludes by establishing various connections between LR(k) grammars and deterministic languages. In particular, the LR(k) condition is a natural analogue, for grammars, of the deterministic condition, for languages.}
}

@article{Earley1970,
author = {Earley, Jay},
title = {An efficient context-free parsing algorithm},
year = {1970},
issue_date = {Feb 1970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {2},
issn = {0001-0782},
url = {https://doi.org/10.1145/362007.362035},
doi = {10.1145/362007.362035},
abstract = {A parsing algorithm which seems to be the most efficient general context-free algorithm known is described. It is similar to both Knuth's LR(k) algorithm and the familiar top-down algorithm. It has a time bound proportional to n3 (where n is the length of the string being parsed) in general; it has an n2 bound for unambiguous grammars; and it runs in linear time on a large class of grammars, which seems to include most practical context-free programming language grammars. In an empirical comparison it appears to be superior to the top-down and bottom-up algorithms studied by Griffiths and Petrick.},
journal = {Commun. ACM},
month = {feb},
pages = {94–102},
numpages = {9},
keywords = {compilers, computational complexity, context-free grammar, parsing, syntax analysis}
}
@Techreport{ Johnsonyacc ,
	title = "Yacc: Yet Another Compiler-Compiler",
	author = "Stephen C. Johnson",
	address = "Murray Hill, New Jersey 07974",
	institution = "AT\&T Bell Laboratories",
	pages = "PS1:15-1 - PS1:15-32",
}

@article{kozen1997kleene,
  title={Kleene algebra with tests},
  author={Kozen, Dexter},
  journal={ACM Transactions on Programming Languages and Systems (TOPLAS)},
  year={1997}
}

@techreport{angus2001kleene,
  title={Kleene algebra with tests and program schematology},
  author={Angus, Allegra and Kozen, Dexter},
  year={2001},
  institution={Cornell University}
}

@inproceedings{hoare2009concurrent,
  title={Concurrent kleene algebra},
  author={Hoare, CAR Tony and M{\"o}ller, Bernhard and Struth, Georg and Wehrman, Ian},
  booktitle={CONCUR},
  year={2009}
}

@inproceedings{anderson2014netkat,
  title={NetKAT: Semantic foundations for networks},
  author={Anderson, Carolyn Jane and Foster, Nate and Guha, Arjun and Jeannin, Jean-Baptiste and Kozen, Dexter and Schlesinger, Cole and Walker, David},
  booktitle={Principles of Programming Languages (POPL)},
  year={2014}
}


@article{KOZEN1994366,
title = {A Completeness Theorem for Kleene Algebras and the Algebra of Regular Events},
journal = {Information and Computation},
volume = {110},
number = {2},
pages = {366-390},
year = {1994},
issn = {0890-5401},
doi = {https://doi.org/10.1006/inco.1994.1037},
url = {https://www.sciencedirect.com/science/article/pii/S0890540184710376},
author = {D. Kozen},
abstract = {We give a finitary axiomatization of the algebra of regular events involving only equations and equational implications. Unlike Salomaa′s axiomatizations, the axiomatization given here is sound for all interpretations over Kleene algebras.}
}

@phdthesis{day1970construction,
  title={Construction of biclosed categories},
  author={Day, Brian John},
  year={1970},
  school={University of New South Wales PhD thesis}
}

@article{kozen1994action,
  title={On action algebras},
  author={Kozen, Dexter},
  journal={Logic and Information Flow},
  year={1994}
}

@inproceedings{kozen2000certification,
  title={Certification of compiler optimizations using Kleene algebra with tests},
  author={Kozen, Dexter and Patron, Maria-Cristina},
  booktitle={International Conference on Computational Logic},
  pages={568--582},
  year={2000},
  organization={Springer}
}

@article{GIRARD19871,
title = {Linear logic},
journal = {Theoretical Computer Science},
volume = {50},
number = {1},
pages = {1-101},
year = {1987},
issn = {0304-3975},
doi = {https://doi.org/10.1016/0304-3975(87)90045-4},
url = {https://www.sciencedirect.com/science/article/pii/0304397587900454},
author = {Jean-Yves Girard},
abstract = {The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.}
}
@article{AhoIndexed,
author = {Aho, Alfred V.},
title = {Indexed Grammars—An Extension of Context-Free Grammars},
year = {1968},
issue_date = {Oct. 1968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {0004-5411},
url = {https://doi.org/10.1145/321479.321488},
doi = {10.1145/321479.321488},
abstract = {A new type of grammar for generating formal languages, called an indexed grammar, is presented. An indexed grammar is an extension of a context-free grammar, and the class of languages generated by indexed grammars has closure properties and decidability results similar to those for context-free languages. The class of languages generated by indexed grammars properly includes all context-free languages and is a proper subset of the class of context-sensitive languages. Several subclasses of indexed grammars generate interesting classes of languages.},
journal = {J. ACM},
month = {oct},
pages = {647–671},
numpages = {25}
}

@InProceedings{leiss,
author="Lei{\ss}, Haas",
editor="B{\"o}rger, Egon
and J{\"a}ger, Gerhard
and Kleine B{\"u}ning, Hans
and Richter, Michael M.",
title="Towards Kleene Algebra with recursion",
booktitle="Computer Science Logic",
year="1992",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="242--256",
abstract="We extend Kozen's theory KA of Kleene Algebra to axiomatize parts of the equational theory of context-free languages, using a least fixed-point operator $\mu$ instead of Kleene's iteration operator*.",
isbn="978-3-540-47285-8"
}

@inproceedings{yoshinaga2002formal,
  title={A Formal Proof of Strong Equivalence for a Grammar Conversion from LTAG to HPSG-style},
  author={Yoshinaga, Naoki and Miyao, Yusuke and Tsujii, Jun’ichi},
  booktitle={Proceedings of the Sixth International Workshop on Tree Adjoining Grammar and Related Frameworks (TAG+ 6)},
  pages={187--192},
  year={2002}
}

@incollection{prattActionLogicPure1991,
	address = {Berlin, Heidelberg},
	title = {Action logic and pure induction},
	volume = {478},
	isbn = {978-3-540-53686-4 978-3-540-46982-7},
	url = {http://link.springer.com/10.1007/BFb0018436},
	abstract = {In Floyd-Hoare logic, programs are dynamic while assertions are static (hold at states). In action logic the two notions become one, with programs viewed as on-the-ﬂy assertions whose truth is evaluated along intervals instead of at states. Action logic is an equational theory ACT conservatively extending the equational theory REG of regular expressions with operations preimplication a→b (had a then b) and postimplication b←a (b if-ever a). Unlike REG, ACT is ﬁnitely based, makes a∗ reﬂexive transitive closure, and has an equivalent Hilbert system. The crucial axiom is that of pure induction, (a→a)∗ = a→a.},
	language = {en},
	urldate = {2024-07-10},
	booktitle = {Logics in {AI}},
	publisher = {Springer Berlin Heidelberg},
	author = {Pratt, Vaughan},
	editor = {Siekmann, J. and Goos, G. and Hartmanis, J. and Van Eijck, J.},
	year = {1991},
	doi = {10.1007/BFb0018436},
	note = {Series Title: Lecture Notes in Computer Science},
	pages = {97--120},
	file = {Pratt - 1991 - Action logic and pure induction.pdf:/Users/stevenschaefer/Zotero/storage/U7JDF77Z/Pratt - 1991 - Action logic and pure induction.pdf:application/pdf},
}

@misc{vakarSyntaxSemanticsLinear2015,
	title = {Syntax and {Semantics} of {Linear} {Dependent} {Types}},
	url = {http://arxiv.org/abs/1405.0033},
	abstract = {A type theory is presented that combines (intuitionistic) linear types with type dependency, thus properly generalising both intuitionistic dependent type theory and full linear logic. A syntax and complete categorical semantics are developed, the latter in terms of (strict) indexed symmetric monoidal categories with comprehension. Various optional type formers are treated in a modular way. In particular, we will see that the historically much-debated multiplicative quantiﬁers and identity types arise naturally from categorical considerations. These new multiplicative connectives are further characterised by several identities relating them to the usual connectives from dependent type theory and linear logic. Finally, one important class of models, given by families with values in some symmetric monoidal category, is investigated in detail.},
	language = {en},
	urldate = {2024-07-10},
	publisher = {arXiv},
	author = {Vákár, Matthijs},
	month = jan,
	year = {2015},
	note = {arXiv:1405.0033 [cs, math]},
	keywords = {Computer Science - Logic in Computer Science, Computer Science - Programming Languages, Mathematics - Category Theory},
	file = {Vákár - 2015 - Syntax and Semantics of Linear Dependent Types.pdf:/Users/stevenschaefer/Zotero/storage/TZU67MKT/Vákár - 2015 - Syntax and Semantics of Linear Dependent Types.pdf:application/pdf},
}

@misc{fu2023twolevellineardependenttype,
      title={A Two-Level Linear Dependent Type Theory},
      author={Qiancheng Fu and Hongwei Xi},
      year={2023},
      eprint={2309.08673},
      archivePrefix={arXiv},
      primaryClass={cs.PL},
      url={https://arxiv.org/abs/2309.08673},
}

@InProceedings{frischCardelli,
author="Frisch, Alain
and Cardelli, Luca",
editor="D{\'i}az, Josep
and Karhum{\"a}ki, Juhani
and Lepist{\"o}, Arto
and Sannella, Donald",
title="Greedy Regular Expression Matching",
booktitle="Automata, Languages and Programming",
year="2004",
publisher="Springer Berlin Heidelberg",
address="Berlin, Heidelberg",
pages="618--629",
abstract="This paper studies the problem of matching sequences against regular expressions in order to produce structured values.",
isbn="978-3-540-27836-8"
}

@inproceedings{firsovCertifiedNormalizationContextFree2015,
	address = {Mumbai India},
	title = {Certified {Normalization} of {Context}-{Free} {Grammars}},
	isbn = {978-1-4503-3296-5},
	url = {https://dl.acm.org/doi/10.1145/2676724.2693177},
	doi = {10.1145/2676724.2693177},
	abstract = {Every context-free grammar can be transformed into an equivalent one in the Chomsky normal form by a sequence of four transformations. In this work on formalization of language theory, we prove formally in the Agda dependently typed programming language that each of these transformations is correct in the sense of making progress toward normality and preserving the language of the given grammar. Also, we show that the right sequence of these transformations leads to a grammar in the Chomsky normal form (since each next transformation preserves the normality properties established by the previous ones) that accepts the same language as the given grammar. As we work in a constructive setting, soundness and completeness proofs are functions converting between parse trees in the normalized and original grammars.},
	language = {en},
	urldate = {2024-05-13},
	booktitle = {Proceedings of the 2015 {Conference} on {Certified} {Programs} and {Proofs}},
	publisher = {ACM},
	author = {Firsov, Denis and Uustalu, Tarmo},
	month = jan,
	year = {2015},
	pages = {167--174},
	file = {Firsov and Uustalu - 2015 - Certified Normalization of Context-Free Grammars.pdf:/Users/stevenschaefer/Zotero/storage/QIZVYCT2/Firsov and Uustalu - 2015 - Certified Normalization of Context-Free Grammars.pdf:application/pdf},
}
@INPROCEEDINGS{egolfVerbatim,
  author={Egolf, Derek and Lasser, Sam and Fisher, Kathleen},
  booktitle={2021 IEEE Security and Privacy Workshops (SPW)},
  title={Verbatim: A Verified Lexer Generator},
  year={2021},
  volume={},
  number={},
  pages={92-100},
  keywords={Performance evaluation;Privacy;Conferences;Tools;Software systems;Generators;Security;lexical analysis;interactive theorem proving},
  doi={10.1109/SPW53761.2021.00022}}

@article{Ouedraogo_2023,
   title={Coqlex: Generating Formally Verified Lexers},
   volume={8},
   ISSN={2473-7321},
   url={http://dx.doi.org/10.22152/programming-journal.org/2024/8/3},
   DOI={10.22152/programming-journal.org/2024/8/3},
   number={1},
   journal={The Art, Science, and Engineering of Programming},
   publisher={Aspect-Oriented Software Association (AOSA)},
   author={Ouedraogo, Wendlasida and Scherer, Gabriel and Strassburger, Lutz},
   year={2023},
   month=jun }

@inproceedings{danielssonTotalParserCombinators2010,
  title = {Total Parser Combinators},
  booktitle = {Proceedings of the 15th {{ACM SIGPLAN}} International Conference on {{Functional}} Programming},
  author = {Danielsson, Nils Anders},
  year = {2010},
  month = sep,
  pages = {285--296},
  publisher = {ACM},
  address = {Baltimore Maryland USA},
  doi = {10.1145/1863543.1863585},
  urldate = {2024-05-08},
  isbn = {978-1-60558-794-3},
  langid = {english},
}

@inproceedings{lasserCoStarVerifiedALL2021,
  title = {{{CoStar}}: A Verified {{ALL}}(*) Parser},
  shorttitle = {{{CoStar}}},
  booktitle = {Proceedings of the 42nd {{ACM SIGPLAN International Conference}} on {{Programming Language Design}} and {{Implementation}}},
  author = {Lasser, Sam and Casinghino, Chris and Fisher, Kathleen and Roux, Cody},
  year = {2021},
  month = jun,
  pages = {420--434},
  publisher = {ACM},
  address = {Virtual Canada},
  doi = {10.1145/3453483.3454053},
  urldate = {2024-05-01},
  isbn = {978-1-4503-8391-2},
  langid = {english},
}

@article{elliottSymbolicAutomaticDifferentiation2021,
  title = {Symbolic and Automatic Differentiation of Languages},
  author = {Elliott, Conal},
  year = {2021},
  month = aug,
  journal = {Proceedings of the ACM on Programming Languages},
  volume = {5},
  number = {ICFP},
  pages = {1--18},
  issn = {2475-1421},
  doi = {10.1145/3473583},
  urldate = {2024-11-10},
  abstract = {Formal languages are usually defined in terms of set theory. Choosing type theory instead gives us languages as type-level predicates over strings. Applying a language to a string yields a type whose elements are language membership proofs describing               how               a string parses in the language. The usual building blocks of languages (including union, concatenation, and Kleene closure) have precise and compelling specifications uncomplicated by operational strategies and are easily generalized to a few general domain-transforming and codomain-transforming operations on predicates.                          A simple characterization of languages (and indeed functions from lists to any type) captures the essential idea behind language ``differentiation'' as used for recognizing languages, leading to a collection of lemmas about type-level predicates. These lemmas are the heart of two dual parsing implementations---using (inductive) regular expressions and (coinductive) tries---each containing the same code but in dual arrangements (with representation and primitive operations trading places). The regular expression version corresponds to symbolic differentiation, while the trie version corresponds to automatic differentiation.             The relatively easy-to-prove properties of type-level languages transfer almost effortlessly to the decidable implementations. In particular, despite the inductive and coinductive nature of regular expressions and tries respectively, we need neither inductive nor coinductive/bisimulation arguments to prove algebraic properties.},
  langid = {english},
}
@inproceedings{EdelmannZippy2020,
author = {Edelmann, Romain and Hamza, Jad and Kun\v{c}ak, Viktor},
title = {Zippy LL(1) parsing with derivatives},
year = {2020},
isbn = {9781450376136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3385412.3385992},
doi = {10.1145/3385412.3385992},
abstract = {In this paper, we present an efficient, functional, and formally verified parsing algorithm for LL(1) context-free expressions based on the concept of derivatives of formal languages. Parsing with derivatives is an elegant parsing technique, which, in the general case, suffers from cubic worst-case time complexity and slow performance in practice. We specialise the parsing with derivatives algorithm to LL(1) context-free expressions, where alternatives can be chosen given a single token of lookahead. We formalise the notion of LL(1) expressions and show how to efficiently check the LL(1) property. Next, we present a novel linear-time parsing with derivatives algorithm for LL(1) expressions operating on a zipper-inspired data structure. We prove the algorithm correct in Coq and present an implementation as a part of Scallion, a parser combinators framework in Scala with enumeration and pretty printing capabilities.},
booktitle = {Proceedings of the 41st ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {1036–1051},
numpages = {16},
keywords = {Zipper, Parsing, LL(1), Formal proof, Derivatives},
location = {London, UK},
series = {PLDI 2020}
}

@article{VezzosiMortbergAbel2019,
author = {Vezzosi, Andrea and M\"{o}rtberg, Anders and Abel, Andreas},
title = {Cubical Agda: A Dependently Typed Programming Language with Univalence and Higher Inductive Types},
year = {2019},
issue_date = {August 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {ICFP},
url = {https://doi.org/10.1145/3341691},
doi = {10.1145/3341691},
abstract = {Proof assistants based on dependent type theory provide expressive languages for both programming and proving within the same system. However, all of the major implementations lack powerful extensionality principles for reasoning about equality, such as function and propositional extensionality. These principles are typically added axiomatically which disrupts the constructive properties of these systems. Cubical type theory provides a solution by giving computational meaning to Homotopy Type Theory and Univalent Foundations, in particular to the univalence axiom and higher inductive types. This paper describes an extension of the dependently typed functional programming language Agda with cubical primitives, making it into a full-blown proof assistant with native support for univalence and a general schema of higher inductive types. These new primitives make function and propositional extensionality as well as quotient types directly definable with computational content. Additionally, thanks also to copatterns, bisimilarity is equivalent to equality for coinductive types. This extends Agda with support for a wide range of extensionality principles, without sacrificing type checking and constructivity.},
journal = {Proc. ACM Program. Lang.},
month = {jul},
articleno = {87},
numpages = {29},
keywords = {Univalence, Cubical Type Theory, Higher Inductive Types, Dependent Pattern Matching}
}

@article{lambek58,
author = {Joachim Lambek},
title = {The Mathematics of Sentence Structure},
journal = {The American Mathematical Monthly},
volume = {65},
number = {3},
pages = {154--170},
year = {1958},
publisher = {Taylor \& Francis},
doi = {10.1080/00029890.1958.11989160},
URL = {https://doi.org/10.1080/00029890.1958.11989160}
}

@inbook{Hofmann_1997,
place={Cambridge},
series={Publications of the Newton Institute},
title={Syntax and Semantics of Dependent Types},
booktitle={Semantics and Logics of Computation},
publisher={Cambridge University Press},
author={Hofmann, Martin},
year={1997}, pages={79–130},
collection={Publications of the Newton Institute}}

@incollection{seely89,
    AUTHOR = {Seely, R. A. G.},
     TITLE = {Linear logic, {$*$}-autonomous categories and cofree
              coalgebras},
 BOOKTITLE = {Categories in computer science and logic ({B}oulder, {CO},
              1987)},
    SERIES = {Contemp. Math.},
    VOLUME = {92},
     PAGES = {371--382},
 PUBLISHER = {Amer. Math. Soc., Providence, RI},
      YEAR = {1989},
      ISBN = {0-8218-5100-4},
   MRCLASS = {03G30 (03B45 18A15)},
  MRNUMBER = {1003210},
MRREVIEWER = {G.\ E.\ Mints and M.\ Gordin},
       DOI = {10.1090/conm/092/1003210},
       URL = {https://doi.org/10.1090/conm/092/1003210},
}

@unpublished{coquandPresheafModel,
author = {Thierry Coquand},
title = {Presheaf model of type theory},
URL = {https://www.cse.chalmers.se/~coquand/presheaf.pdf}
}


@article{lmcs:7713,
  TITLE = {{Multimodal Dependent Type Theory}},
  AUTHOR = {Daniel Gratzer and G. A. Kavvos and Andreas Nuyts and Lars Birkedal},
  URL = {https://lmcs.episciences.org/7713},
  DOI = {10.46298/lmcs-17(3:11)2021},
  JOURNAL = {{Logical Methods in Computer Science}},
  VOLUME = {{Volume 17, Issue 3}},
  YEAR = {2021},
  MONTH = Jul,
  KEYWORDS = {Computer Science - Logic in Computer Science},
}

@article{girard_linear_1987,
	title = {Linear logic},
	volume = {50},
	issn = {0304-3975},
	url = {https://www.sciencedirect.com/science/article/pii/0304397587900454},
	doi = {https://doi.org/10.1016/0304-3975(87)90045-4},
	abstract = {The familiar connective of negation is broken into two operations: linear negation which is the purely negative part of negation and the modality “of course” which has the meaning of a reaffirmation. Following this basic discovery, a completely new approach to the whole area between constructive logics and programmation is initiated.},
	number = {1},
	journal = {Theoretical Computer Science},
	author = {Girard, Jean-Yves},
	year = {1987},
	pages = {1--101},
}

@Book{hottbook,
  author =    {The {Univalent Foundations Program}},
  title =     {Homotopy Type Theory: Univalent Foundations of Mathematics},
  publisher = {\url{https://homotopytypetheory.org/book}},
  address =   {Institute for Advanced Study},
  year =      2013}

@inproceedings{nakov_quantitative_2022,
	title = {Quantitative {Polynomial} {Functors}},
	copyright = {https://creativecommons.org/licenses/by/4.0/legalcode},
	url = {https://drops.dagstuhl.de/entities/document/10.4230/LIPIcs.TYPES.2021.10},
	doi = {10.4230/LIPIcs.TYPES.2021.10},
	abstract = {We investigate containers and polynomial functors in Quantitative Type Theory, and give initial algebra semantics of inductive data types in the presence of linearity. We show that reasoning by induction is supported, and equivalent to initiality, also in the linear setting.},
	language = {en},
	urldate = {2024-11-13},
	booktitle = {27th {International} {Conference} on {Types} for {Proofs} and {Programs} ({TYPES} 2021)},
	publisher = {Schloss Dagstuhl – Leibniz-Zentrum für Informatik},
	author = {Nakov, Georgi and Nordvall Forsberg, Fredrik},
	year = {2022},
	pages = {10:1--10:22},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/U45DLSHZ/Nakov and Nordvall Forsberg - 2022 - Quantitative Polynomial Functors.pdf:application/pdf},
}

@inproceedings{jung_higher-order_2016,
	address = {New York, NY, USA},
	series = {{ICFP} 2016},
	title = {Higher-order ghost state},
	isbn = {978-1-4503-4219-3},
	url = {https://dl.acm.org/doi/10.1145/2951913.2951943},
	doi = {10.1145/2951913.2951943},
	abstract = {The development of concurrent separation logic (CSL) has sparked a long line of work on modular verification of sophisticated concurrent programs. Two of the most important features supported by several existing extensions to CSL are higher-order quantification and custom ghost state. However, none of the logics that support both of these features reap the full potential of their combination. In particular, none of them provide general support for a feature we dub "higher-order ghost state": the ability to store arbitrary higher-order separation-logic predicates in ghost variables.  In this paper, we propose higher-order ghost state as a interesting and useful extension to CSL, which we formalize in the framework of Jung et al.'s recently developed Iris logic. To justify its soundness, we develop a novel algebraic structure called CMRAs ("cameras"), which can be thought of as "step-indexed partial commutative monoids". Finally, we show that Iris proofs utilizing higher-order ghost state can be effectively formalized in Coq, and discuss the challenges we faced in formalizing them.},
	urldate = {2024-11-14},
	booktitle = {Proceedings of the 21st {ACM} {SIGPLAN} {International} {Conference} on {Functional} {Programming}},
	publisher = {Association for Computing Machinery},
	author = {Jung, Ralf and Krebbers, Robbert and Birkedal, Lars and Dreyer, Derek},
	month = sep,
	year = {2016},
	pages = {256--269},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/T7F4GFGD/Jung et al. - 2016 - Higher-order ghost state.pdf:application/pdf},
}

@inproceedings{leis_towards_1992,
	address = {Berlin, Heidelberg},
	title = {Towards {Kleene} {Algebra} with recursion},
	isbn = {978-3-540-47285-8},
	doi = {10.1007/BFb0023771},
	abstract = {We extend Kozen's theory KA of Kleene Algebra to axiomatize parts of the equational theory of context-free languages, using a least fixed-point operator μ instead of Kleene's iteration operator*.},
	language = {en},
	booktitle = {Computer {Science} {Logic}},
	publisher = {Springer},
	author = {Leiß, Haas},
	editor = {Börger, Egon and Jäger, Gerhard and Kleine Büning, Hans and Richter, Michael M.},
	year = {1992},
	keywords = {Continuous Model, Equational Theory, Finite Automaton, Regular Expression, Regular Language},
	pages = {242--256},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/ECBXMTEA/Leiß - 1992 - Towards Kleene Algebra with recursion.pdf:application/pdf},
}

@article{rosenkrantz_properties_1970,
	title = {Properties of deterministic top-down grammars},
	volume = {17},
	issn = {0019-9958},
	url = {https://www.sciencedirect.com/science/article/pii/S0019995870904468},
	doi = {10.1016/S0019-9958(70)90446-8},
	abstract = {The class of context-free grammars that can be deterministically parsed in a top down manner with a fixed amount of look-ahead is investigated. These grammars, called LL(k) grammars where k is the amount of look-ahead are defined and a procedure is given for determining if a context-free grammar is LL(k) for a given value of k. A procedure is given for eliminating the ε-rules from an LL(k) grammar at the cost of increasing k by 1. There exist cases in which this increase is inevitable. A procedure is given for obtaining a deterministic push-down machine to recognize a given LL(k) grammar and it is shown that the equivalence problem is decidable for LL(k) grammars. Additional properties are also given.},
	number = {3},
	urldate = {2024-11-14},
	journal = {Information and Control},
	author = {Rosenkrantz, D. J. and Stearns, R. E.},
	month = oct,
	year = {1970},
	pages = {226--256},
	file = {ScienceDirect Full Text PDF:/Users/maxsnew/Zotero/storage/GVZE42GJ/Rosenkrantz and Stearns - 1970 - Properties of deterministic top-down grammars.pdf:application/pdf;ScienceDirect Snapshot:/Users/maxsnew/Zotero/storage/BUBJ7YHA/S0019995870904468.html:text/html},
}

@inproceedings{gambino_wellfounded_2004,
	address = {Berlin, Heidelberg},
	title = {Wellfounded {Trees} and {Dependent} {Polynomial} {Functors}},
	isbn = {978-3-540-24849-1},
	doi = {10.1007/978-3-540-24849-1_14},
	abstract = {We set out to study the consequences of the assumption of types of wellfounded trees in dependent type theories. We do so by investigating the categorical notion of wellfounded tree introduced in [16]. Our main result shows that wellfounded trees allow us to define initial algebras for a wide class of endofunctors on locally cartesian closed categories.},
	language = {en},
	booktitle = {Types for {Proofs} and {Programs}},
	publisher = {Springer},
	author = {Gambino, Nicola and Hyland, Martin},
	editor = {Berardi, Stefano and Coppo, Mario and Damiani, Ferruccio},
	year = {2004},
	keywords = {Forgetful Functor, Left Adjoint, Monoidal Category, Natural Transformation, Type Theory},
	pages = {210--225},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/6FMSQHE3/Gambino and Hyland - 2004 - Wellfounded Trees and Dependent Polynomial Functors.pdf:application/pdf},
}

@article{altenkirch_indexed_2015,
	title = {Indexed containers},
	volume = {25},
	issn = {0956-7968, 1469-7653},
	url = {https://www.cambridge.org/core/journals/journal-of-functional-programming/article/indexed-containers/FB9C7DC88A65E7529D39554379D9765F},
	doi = {10.1017/S095679681500009X},
	abstract = {We show that the syntactically rich notion of strictly positive families can be reduced to a core type theory with a fixed number of type constructors exploiting the novel notion of indexed containers. As a result, we show indexed containers provide normal forms for strictly positive families in much the same way that containers provide normal forms for strictly positive types. Interestingly, this step from containers to indexed containers is achieved without having to extend the core type theory. Most of the construction presented here has been formalized using the Agda system.},
	language = {en},
	urldate = {2024-11-14},
	journal = {Journal of Functional Programming},
	author = {Altenkirch, Thorsten and Ghani, Neil and Hancock, Peter and Mcbride, Conor and Morris, Peter},
	month = jan,
	year = {2015},
	pages = {e5},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/N9FBLA7U/Altenkirch et al. - 2015 - Indexed containers.pdf:application/pdf},
}

@software{The_Agda_Community_Cubical_Agda_Library_2024,
author = {{The Agda Community}},
month = feb,
title = {{Cubical Agda Library}},
url = {https://github.com/agda/cubical},
version = {0.7},
year = {2024}
}

@INPROCEEDINGS{7174865,
  author={O'Hearn, Peter},
  booktitle={2015 30th Annual ACM/IEEE Symposium on Logic in Computer Science}, 
  title={From Categorical Logic to Facebook Engineering}, 
  year={2015},
  volume={},
  number={},
  pages={17-20},
  keywords={Semantics;Facebook;Computer science;Mathematical model;Cognition;Syntactics;Shape},
  doi={10.1109/LICS.2015.11}}
@inproceedings{reynolds_separation_2002,
	title = {Separation logic: a logic for shared mutable data structures},
	shorttitle = {Separation logic},
	url = {https://ieeexplore.ieee.org/document/1029817},
	doi = {10.1109/LICS.2002.1029817},
	abstract = {In joint work with Peter O'Hearn and others, based on early ideas of Burstall, we have developed an extension of Hoare logic that permits reasoning about low-level imperative programs that use shared mutable data structure. The simple imperative programming language is extended with commands (not expressions) for accessing and modifying shared structures, and for explicit allocation and deallocation of storage. Assertions are extended by introducing a "separating conjunction" that asserts that its subformulas hold for disjoint parts of the heap, and a closely related "separating implication". Coupled with the inductive definition of predicates on abstract data structures, this extension permits the concise and flexible description of structures with controlled sharing. In this paper, we survey the current development of this program logic, including extensions that permit unrestricted address arithmetic, dynamically allocated arrays, and recursive procedures. We also discuss promising future directions.},
	urldate = {2024-11-14},
	booktitle = {Proceedings 17th {Annual} {IEEE} {Symposium} on {Logic} in {Computer} {Science}},
	author = {Reynolds, J.C.},
	month = jul,
	year = {2002},
	note = {ISSN: 1043-6871},
	keywords = {Arithmetic, Artificial intelligence, Bibliographies, Computer languages, Computer science, Data structures, Logic arrays, Logic programming, Programmable logic arrays, Reflection},
	pages = {55--74},
	file = {Full Text PDF:/Users/maxsnew/Zotero/storage/9LIXHB29/Reynolds - 2002 - Separation logic a logic for shared mutable data structures.pdf:application/pdf},
}

@book{Montague1974-MONFPS,
	address = {New Haven,},
	author = {Richard Montague},
	editor = {},
	publisher = {Yale University Press},
	title = {Formal Philosophy: Selected Papers of Richard Montague},
	year = {1974}
}

@incollection{buszkowskiTypeLogicsGrammar2003,
	address = {Dordrecht},
	title = {Type {Logics} in {Grammar}},
	volume = {21},
	isbn = {978-90-481-6414-1 978-94-017-3598-8},
	url = {http://link.springer.com/10.1007/978-94-017-3598-8_12},
	language = {en},
	urldate = {2024-08-07},
	booktitle = {Trends in {Logic}},
	publisher = {Springer Netherlands},
	author = {Buszkowski, W.},
	editor = {Wójcicki, Ryszard and Mundici, Daniele and Orłowska, Ewa and Priest, Graham and Segerberg, Krister and Urquhart, Alasdair and Wansing, Heinrich and Hendricks, Vincent F. and Malinowski, Jacek},
	year = {2003},
	doi = {10.1007/978-94-017-3598-8_12},
	note = {Series Title: Trends in Logic},
	pages = {337--382},
	file = {Buszkowski - 2003 - Type Logics in Grammar.pdf:/Users/stevenschaefer/Zotero/storage/LU7PLCX5/Buszkowski - 2003 - Type Logics in Grammar.pdf:application/pdf},
}
